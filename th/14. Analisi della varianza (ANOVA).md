# Analisi della varianza (ANOVA)

L’analisi della varianza, o ANOVA, è una tecnica statistica pensata per valutare se una variabile numerica $Y$ dipenda significativamente da una o più variabili di ingresso di tipo **categorico**. A differenza della regressione tradizionale, dove le covariate sono numeriche, qui le variabili esplicative assumono un numero limitato di categorie (come gruppi, livelli o etichette).

Il modello generale prevede che l’output $Y$ dipenda dalle variabili categoriche con **rumore additivo gaussiano omoschedastico**, cioè con varianza costante e distribuzione normale. Esistono diverse versioni dell’ANOVA a seconda del numero di fattori coinvolti:

- **ANOVA a una via**: prevede un solo fattore categorico, ad esempio il tipo di ospedale in cui è avvenuto il parto.
- **ANOVA a due vie**: coinvolge due fattori categorici, ad esempio ospedale e tipo di trattamento, con una singola osservazione per ogni combinazione.
- **ANOVA a due vie con repliche**: quando ci sono più osservazioni per ogni combinazione dei due fattori.



## ANOVA a una via

Nel caso più semplice, ogni osservazione $Y_{ij}$ è associata a un gruppo $i$ (cioè a una categoria del fattore) e a una replica $j$ all’interno di quel gruppo. Si assume che:

$$
Y_{ij} = \mu_i + \varepsilon_{ij}, \quad \text{con } \varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2),
$$

dove ogni gruppo ha una propria media $\mu_i$ ma con varianza comune $\sigma^2$. L’indice $i$ varia da 1 a $m$ (numero di gruppi), mentre $j$ va da 1 a $n_i$ (numero di osservazioni nel gruppo $i$).

L'obiettivo è verificare se almeno una delle medie $\mu_i$ differisca dalle altre. In altre parole, se $Y$ **dipende dal gruppo** di appartenenza.



## Stima dei parametri

Per ogni gruppo si può calcolare la media campionaria $\bar Y_i$ e la varianza campionaria $S_i^2$. Le medie hanno distribuzione:

$$
\bar Y_i \sim \mathcal{N}\left( \mu_i, \frac{\sigma^2}{n_i} \right),
$$

mentre ciascuna $S_i^2$ è uno stimatore non distorto della varianza comune $\sigma^2$.

Per ottenere una stima globale della varianza, si utilizza la **devianza within** (cioè interna ai gruppi), definita come:

$$
\mathrm{SS}_W = \sum_{i=1}^m \sum_{j=1}^{n_i} (Y_{ij} - \bar Y_i)^2.
$$

Da qui, si ottiene la stima pooled della varianza:

$$
S_p^2 = \frac{\mathrm{SS}_W}{N - m},
$$

dove $N = \sum_{i=1}^m n_i$ è il numero totale di osservazioni. Questo stimatore segue (sotto ipotesi) una distribuzione chi-quadrato:

$$
\frac{(N - m) S_p^2}{\sigma^2} \sim \chi^2_{N - m}.
$$

Parallelamente, si calcola anche la **devianza totale**:

$$
\mathrm{SS}_Y = \sum_{i=1}^m \sum_{j=1}^{n_i} (Y_{ij} - \bar Y)^2,
$$

dove $\bar Y$ è la media complessiva di tutte le osservazioni. La **devianza between**, cioè tra gruppi, è allora:

$$
\mathrm{SS}_B = \sum_{i=1}^m n_i (\bar Y_i - \bar Y)^2.
$$

Tutti e tre questi termini sono legati dalla classica **identità delle devianze**:

$$
\mathrm{SS}_Y = \mathrm{SS}_B + \mathrm{SS}_W.
$$



## Il test ANOVA

Per verificare se le medie $\mu_i$ siano tutte uguali, si imposta il seguente test:

$$
H_0: \mu_1 = \mu_2 = \dots = \mu_m, \quad \text{contro} \quad H_A: \text{non tutte le } \mu_i \text{ sono uguali}.
$$

La statistica del test è data da:

$$
F = \frac{S_B^2}{S_p^2} = \frac{\mathrm{SS}_B / (m - 1)}{\mathrm{SS}_W / (N - m)}.
$$

Sotto $H_0$, questa quantità segue una distribuzione $F$ con $m-1$ e $N - m$ gradi di libertà:

$$
F \sim F(m - 1,\ N - m).
$$

Se il valore osservato di $F$ è troppo grande rispetto alla distribuzione teorica (cioè se $F > F_{\alpha}(m - 1,\ N - m)$ per un certo livello di significatività $\alpha$), si rifiuta l’ipotesi nulla e si conclude che almeno un gruppo differisce.



## Aspetti operativi

I dati per l’ANOVA possono essere raccolti in due formati principali. Il **formato wide** prevede una colonna per ogni gruppo, mentre il **formato long (stacked)** è più adatto per software statistici e contiene una colonna con l’etichetta del gruppo e una colonna con la variabile di interesse.

Dopo aver effettuato l’ANOVA, è buona prassi controllare i **residui** per verificare che le ipotesi del modello siano soddisfatte. In particolare, è importante che:

- i residui siano distribuiti normalmente,
- la varianza sia costante tra i gruppi (omoschedasticità),
- non ci siano outlier evidenti.

Se queste condizioni non sono rispettate, si possono applicare **trasformazioni** sulla variabile $Y$, come logaritmo o radice quadrata, per migliorare l’aderenza ai presupposti.

Infine, se il test ANOVA non è significativo, si può trattare l’intero dataset come un singolo campione proveniente da una distribuzione gaussiana comune, ignorando il fattore categoriale.

