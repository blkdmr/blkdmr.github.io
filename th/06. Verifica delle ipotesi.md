# Verifica delle ipotesi

Supponiamo, ancora una volta, di disporre di un campione aleatorio proveniente da una distribuzione che ci è nota tranne che per uno o più parametri incogniti. La nuova chiave di lettura non consiste più nello stimare direttamente questi parametri, ma piuttosto nell’utilizzare il campione per **verificare un’ipotesi** che li riguarda.

Un’**ipotesi statistica** è un’affermazione su uno o più parametri della distribuzione di popolazione. Si parla di "ipotesi" proprio perché, a priori, non sappiamo se essa sia compatibile o meno con i valori del campione osservato.

**Nota.** Quando accettiamo (o rifiutiamo) un’ipotesi, non stiamo dicendo che essa sia necessariamente vera (o falsa), ma solo che i dati raccolti sono accettabilmente in accordo (o in disaccordo) con essa.

## Livelli di significatività

Data una popolazione con distribuzione $F_\theta$, che dipende da un parametro incognito $\theta$, supponiamo di voler verificare una certa ipotesi su $\theta$, detta **ipotesi nulla**, indicata con $H_0$.

Ad esempio, se $F_\theta$ è una distribuzione normale con media $\theta$ e varianza $1$, due possibili ipotesi nulle sono:

1. $H_0 : \theta = 1$
2. $H_0 : \theta \le 1$

La prima ipotesi afferma che la popolazione ha distribuzione $\mathcal{N}(1,1)$; la seconda afferma che la media non supera 1, pur rimanendo all’interno di una distribuzione normale con varianza 1.

- Nel primo caso ($H_0 : \theta = 1$), l’ipotesi **determina completamente** la distribuzione → si parla di **ipotesi semplice**.  
- Nel secondo caso, la distribuzione non è completamente specificata → si parla di **ipotesi composta**.

Supponiamo ora di avere un campione aleatorio $X_1, \dots, X_n$ proveniente dalla popolazione, e di volerlo usare per eseguire un **test statistico** sull’ipotesi nulla $H_0$. Poiché la decisione si basa solo sui valori osservati, definiamo una **regione critica** $C$ nello spazio $n$-dimensionale: se $(X_1, \dots, X_n) \in C$, rifiutiamo $H_0$; altrimenti, l'accettiamo.

Il test è quindi definito come:
- Accetta $H_0$ se $(X_1, \dots, X_n) \notin C$
- Rifiuta $H_0$ se $(X_1, \dots, X_n) \in C$

Durante un test statistico, possono verificarsi due tipi di errore:
- **Errore di I specie:** si rifiuta $H_0$ quando è vera
- **Errore di II specie:** si accetta $H_0$ quando è falsa

L’obiettivo non è stabilire con certezza se $H_0$ sia vera o falsa, ma valutare se sia compatibile con i dati osservati. Per questo, è comune **essere cauti nel rifiutare $H_0$**, richiedendo che i dati osservati siano *molto improbabili* se $H_0$ fosse vera.

Questo si ottiene specificando un valore $\alpha$, detto **livello di significatività**, e imponendo che la probabilità di errore di prima specie non superi $\alpha$:

> Un test di livello $\alpha$ ha:  
> $$P(\text{rifiutare } H_0 \mid H_0 \text{ vera}) \le \alpha$$

## Verifica di ipotesi sulla media di una popolazione normale

Supponiamo di avere un campione aleatorio $X_1, \dots, X_n$ proveniente da una popolazione normale con media incognita $\mu$ e varianza **nota** $\sigma^2$.

Vogliamo verificare:

- Ipotesi nulla: $H_0 : \mu = \mu_0$
- Ipotesi alternativa: $H_1 : \mu \neq \mu_0$

Poiché $\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i$ è uno stimatore naturale di $\mu$, ha senso accettare $H_0$ se $\bar{X}$ non è troppo distante da $\mu_0$.

Definiamo la **regione critica** come:

$$
C := \{(X_1, \dots, X_n) : |\bar{X} - \mu_0| > c\}
$$

Il valore di $c$ viene scelto in modo da garantire che la **probabilità di errore di I specie** sia esattamente $\alpha$:

$$
\alpha = P_{\mu_0}(|\bar{X} - \mu_0| > c)
$$

Poiché, sotto $H_0$, $\bar{X} \sim \mathcal{N}(\mu_0, \sigma^2/n)$, possiamo standardizzare:

$$
\dfrac{\bar{X} - \mu_0}{\sigma/\sqrt{n}} \sim^{\mu_0} Z \sim \mathcal{N}(0,1)
$$

Allora,

$$
\alpha = P_{\mu_0}\left(\left|\dfrac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}\right| > \dfrac{c\sqrt{n}}{\sigma}\right)
= 2P\left(Z > \dfrac{c\sqrt{n}}{\sigma}\right)
$$

Per definizione di quantile $z_{\alpha/2}$, si ha:

$$
P(Z > z_{\alpha/2}) = \alpha/2 \quad \Rightarrow \quad \dfrac{c\sqrt{n}}{\sigma} = z_{\alpha/2}
$$

Quindi:

$$
c = z_{\alpha/2} \cdot \dfrac{\sigma}{\sqrt{n}}
$$

### Decisione del test

Il test al livello di significatività $\alpha$ rifiuta $H_0$ se:

$$
|\bar{X} - \mu_0| > z_{\alpha/2} \cdot \dfrac{\sigma}{\sqrt{n}}
$$

Equivalente a:

$$
\left|\dfrac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}\right| > z_{\alpha/2}
$$

Altrimenti, si accetta $H_0$.

**Nota.** La regione di accettazione della statistica del test è un intervallo centrato in 0, simmetrico rispetto allo stesso.
