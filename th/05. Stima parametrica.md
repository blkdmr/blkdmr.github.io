# Stima parametrica

Consideriamo un campione aleatorio $X_1, \dots, X_n$ estratto da una distribuzione $F_\theta$, la quale dipende da un vettore di parametri incogniti $\theta$ (ad esempio, una distribuzione di Poisson in cui il valore di $\lambda$ non è noto). 

A differenza del calcolo delle probabilità, dove spesso si assume che le distribuzioni siano note, **in statistica l'obiettivo principale è fare inferenza**, cioè ottenere informazioni sui parametri sconosciuti a partire dai dati osservati.

## Stimatori di massima verosimiglianza

Una qualunque statistica il cui scopo sia fornire una stima di un parametro $\theta$ si chiama **stimatore** di $\theta$. Gli stimatori sono quindi variabili aleatorie. Il valore numerico assunto da uno stimatore in seguito all’osservazione di un campione è detto **stima**.

Siano $X_1, \dots, X_n$ variabili aleatorie con distribuzione congiunta nota, eccetto per un parametro incognito $\theta$. Il problema è stimare $\theta$ a partire dai valori osservati di queste variabili.

Una classe particolarmente utile di stimatori è quella degli **stimatori di massima verosimiglianza**. Indichiamo con $f(x_1, \dots, x_n | \theta)$ la funzione di massa (se le variabili sono discrete) o di densità (se continue) congiunta di $X_1, \dots, X_n$. 

Se interpretiamo $f(x_1, \dots, x_n | \theta)$ come la **verosimiglianza** (cioè quanto è "plausibile" osservare i dati $x_1, \dots, x_n$ dato un certo valore di $\theta$), allora sembra ragionevole scegliere come **stima di $\theta$** quel valore che rende massima questa verosimiglianza. In altre parole, lo **stimatore di massima verosimiglianza** $\hat{\theta}$ è il valore di $\theta$ che massimizza $f(x_1, \dots, x_n | \theta)$, considerando fissati i dati osservati $x_1, \dots, x_n$.

**Nota.** La funzione $f(x_1, \dots, x_n | \theta)$, vista in funzione di $\theta$ con i dati fissati, è chiamata **funzione di likelihood**.

Per semplificare i calcoli, si sfrutta spesso il fatto che **massimizzare** $f(x_1, \dots, x_n | \theta)$ è equivalente a **massimizzare il suo logaritmo**: le due funzioni hanno lo stesso punto di massimo. Quindi possiamo trovare $\hat{\theta}$ anche massimizzando:

$$\log\left[f(x_1, \dots, x_n | \theta)\right]$$

**Nota.** Questa è detta **funzione di log-likelihood**.

## Intervalli di confidenza

Sia $X_1, \dots, X_n$ un campione estratto da una popolazione normalmente distribuita, con **media incognita** $\mu$ e **varianza nota** $\sigma^2$. Lo stimatore di massima verosimiglianza per $\mu$ è la **media campionaria**:

$$\bar{X} := \frac{1}{n} \sum_i X_i$$

Questo non significa che $\bar{X}$ coinciderà esattamente con $\mu$, ma che sarà "vicina" con alta probabilità. Per questo motivo, spesso si preferisce dare **un intervallo** di valori plausibili per $\mu$ anziché una sola stima puntuale. Questo intervallo è detto **intervallo di confidenza**.

Per costruirlo, si sfrutta la distribuzione dello stimatore puntuale. In particolare:

Se $\sigma$ è nota, si usa la distribuzione normale standard. L’intervallo di confidenza al 95% è dato da:

$$IC = \bar{x} \pm z \cdot \frac{\sigma}{\sqrt{n}}$$

dove $z$ è il valore critico corrispondente al livello di confidenza desiderato. Per un livello del 95%, si ha $z = 1{,}96$, perché:

$$P(-1{,}96 \leq Z \leq 1{,}96) = 0{,}95$$

cioè il 95% dell’area sotto la curva normale standard è compreso tra $-1{,}96$ e $+1{,}96$.

Se invece $\sigma$ **non è nota**, si utilizza la deviazione standard campionaria $s$ come stima di $\sigma$, e la distribuzione $t$ di Student con $n - 1$ gradi di libertà. In questo caso:

$$IC = \bar{x} \pm t \cdot \frac{s}{\sqrt{n}}$$

dove $t$ è il valore critico corrispondente al livello di confidenza e ai gradi di libertà.

### Riepilogo dei passaggi:

1. **Calcolo della media campionaria**  
   $$\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i$$

2. **Calcolo dell'errore standard (SE)**  
   - Se $\sigma$ è noto: $$SE = \frac{\sigma}{\sqrt{n}}$$  
   - Se $\sigma$ non è noto: $$SE = \frac{s}{\sqrt{n}}$$

3. **Determinazione del valore critico**  
   - Per livello di confidenza del 95%, $z = 1{,}96$

4. **Calcolo dei limiti dell’intervallo di confidenza**  
   $$IC = (\bar{x} - z \cdot SE,\ \bar{x} + z \cdot SE)$$

Per capire meglio il perché del valore $z = 1{,}96$: la distribuzione normale standard ha media $0$ e deviazione standard $1$. Il livello di confidenza del 95% implica che vogliamo catturare il 95% dell’area sotto la curva, centrato attorno allo 0. Questo lascia il 5% fuori, diviso tra le due code: il 2,5% a sinistra e il 2,5% a destra. 

Cercando nella tavola della normale, troviamo che:

$$P(Z \leq 1{,}96) = 0{,}975$$

Il che implica che tra $-1{,}96$ e $+1{,}96$ è contenuto esattamente il 95% della distribuzione.
