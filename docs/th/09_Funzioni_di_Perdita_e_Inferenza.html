<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>funzioni_di_perdita_e_inferenza – IML</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d1aacd23651da4810371d54805babc2f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../th/01. Richiami di probabilità.html">Theory</a></li><li class="breadcrumb-item"><a href="../th/09_Funzioni_di_Perdita_e_Inferenza.html">Funzioni di Perdita e Inferenza</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">IML</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/01. Richiami di probabilità.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Richiami di Probabilità</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/02. Variabili aleatorie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Variabili Aleatorie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/03. Modelli di variabili aleatorie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modelli di variabili aleatorie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/04. La distribuzione delle statistiche campionarie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La distribuzione delle statistiche campionarie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/05. Stima parametrica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stima parametrica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/06. Verifica delle ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Verifica delle ipotesi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/07. Vettori aleatori.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vettori aleatori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/08_Analisi_delle_componenti_principali.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analisi delle componenti principali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/09_Funzioni_di_Perdita_e_Inferenza.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Funzioni di Perdita e Inferenza</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/10. Ancora sul teorema di Cochran.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ancora sul teorema di Cochran</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/11. Selezione di Variabili e Regolarizzazione nella Regressione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selezione di Variabili e Regolarizzazione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/12_gestione_delle_variabili.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gestione delle variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/13_Regressione_logistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regressione logistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/14_Analisi_della_varianza.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analisi della varianza</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/15. ANOVA a due vie (con o senza repliche).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA a due vie (con o senza repliche)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/16_Test_del_chi-quadro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Test del Chi-quadro</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Laboratory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/01_02_Introduzione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-02: Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/03_04_Gaussiane.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">03-04: Gaussiane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/05_06_Limite_Centrale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">05-06: Limite Centrale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/07_08_EDA_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">07-08: EDA e PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/09_10_Generazione_campioni.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">09-10: Generazione campioni da distribuzione scelta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/11_12_MLE_Regressione_Abalone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11-12: MLE e Regressione Abalone</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/13_14_Outlier_Regressione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13-14: Outlier e Regressione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/15_16_OLS_Abalone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15-16: OLS (Abalone)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Exams</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-01: Analisi distribuzione Dirichlet</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-02: EDA e PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-03: Classificazione Logistic Regression e PyTorch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-04: Regressione con OLS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-05: Minimizzazione con SciPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_2_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">02-01: Analisi distribuzione custom</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_2_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">02-02: Analisi dataset Gallstone</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#funzioni-di-perdita-e-inferenza" id="toc-funzioni-di-perdita-e-inferenza" class="nav-link active" data-scroll-target="#funzioni-di-perdita-e-inferenza">Funzioni di Perdita e Inferenza</a>
  <ul class="collapse">
  <li><a href="#cross-entropy-loss" id="toc-cross-entropy-loss" class="nav-link" data-scroll-target="#cross-entropy-loss">Cross-Entropy Loss</a>
  <ul class="collapse">
  <li><a href="#caso-senza-dipendenza-da-x" id="toc-caso-senza-dipendenza-da-x" class="nav-link" data-scroll-target="#caso-senza-dipendenza-da-x">Caso senza dipendenza da <span class="math inline">\(x\)</span></a></li>
  <li><a href="#caso-con-dipendenza-da-x" id="toc-caso-con-dipendenza-da-x" class="nav-link" data-scroll-target="#caso-con-dipendenza-da-x">Caso con dipendenza da <span class="math inline">\(x\)</span></a></li>
  <li><a href="#cross-entropy-come-funzione-di-perdita" id="toc-cross-entropy-come-funzione-di-perdita" class="nav-link" data-scroll-target="#cross-entropy-come-funzione-di-perdita">Cross-Entropy come funzione di perdita</a></li>
  </ul></li>
  <li><a href="#mean-squared-error-loss-mse" id="toc-mean-squared-error-loss-mse" class="nav-link" data-scroll-target="#mean-squared-error-loss-mse">Mean Squared Error Loss (MSE)</a>
  <ul class="collapse">
  <li><a href="#parametri-costanti" id="toc-parametri-costanti" class="nav-link" data-scroll-target="#parametri-costanti">Parametri costanti</a></li>
  <li><a href="#caso-omoschedastico-varianza-costante" id="toc-caso-omoschedastico-varianza-costante" class="nav-link" data-scroll-target="#caso-omoschedastico-varianza-costante">Caso omoschedastico (varianza costante)</a></li>
  <li><a href="#caso-eteroschedastico-dipendenza-completa-da-x" id="toc-caso-eteroschedastico-dipendenza-completa-da-x" class="nav-link" data-scroll-target="#caso-eteroschedastico-dipendenza-completa-da-x">Caso eteroschedastico (dipendenza completa da <span class="math inline">\(x\)</span>)</a></li>
  </ul></li>
  <li><a href="#regressione-lineare-semplice" id="toc-regressione-lineare-semplice" class="nav-link" data-scroll-target="#regressione-lineare-semplice">Regressione Lineare Semplice</a></li>
  <li><a href="#teorema-di-cochran" id="toc-teorema-di-cochran" class="nav-link" data-scroll-target="#teorema-di-cochran">Teorema di Cochran</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../th/01. Richiami di probabilità.html">Theory</a></li><li class="breadcrumb-item"><a href="../th/09_Funzioni_di_Perdita_e_Inferenza.html">Funzioni di Perdita e Inferenza</a></li></ol></nav></header>




<section id="funzioni-di-perdita-e-inferenza" class="level1">
<h1>Funzioni di Perdita e Inferenza</h1>
<section id="cross-entropy-loss" class="level2">
<h2 class="anchored" data-anchor-id="cross-entropy-loss">Cross-Entropy Loss</h2>
<p>La <strong>Cross-Entropy Loss</strong> (entropia incrociata) è una funzione di perdita utilizzata quando la variabile target è <strong>categorica</strong>, in particolare nei problemi di classificazione multiclasse. Il suo impiego è strettamente connesso a modelli probabilistici che, per ogni osservazione, stimano una distribuzione di probabilità sulle classi possibili.</p>
<p>Si consideri un dataset formato da <span class="math inline">\(n\)</span> osservazioni e <span class="math inline">\(m\)</span> categorie. Ogni osservazione appartiene a una sola categoria ed è rappresentata tramite un vettore <strong>one-hot</strong> <span class="math inline">\(b(i) \in \{0,1\}^m\)</span>, tale che <span class="math inline">\(b_j(i)=1\)</span> se l’osservazione <span class="math inline">\(i\)</span> appartiene alla classe <span class="math inline">\(j\)</span> e <span class="math inline">\(b_j(i)=0\)</span> altrimenti.</p>
<p>Indichiamo con <span class="math inline">\(p_j(i)\)</span> la probabilità che l’osservazione <span class="math inline">\(i\)</span> appartenga alla classe <span class="math inline">\(j\)</span>. Per ogni <span class="math inline">\(i\)</span>, queste quantità definiscono una distribuzione discreta, quindi soddisfano i vincoli <span class="math display">\[
p_j(i) \ge 0,
\qquad
\sum_{j=1}^m p_j(i) = 1.
\]</span></p>
<p>Grazie alla codifica one-hot, la probabilità dell’osservazione <span class="math inline">\(i\)</span> può essere scritta in forma compatta come <span class="math display">\[
P(Y(i)=j) = p_j(i) = \prod_{k=1}^m p_k(i)^{b_k(i)}.
\]</span> Il prodotto seleziona automaticamente il termine corrispondente alla classe osservata, poiché tutti gli altri esponenti sono nulli.</p>
<p>La <strong>log-verosimiglianza</strong> dell’intero campione si ottiene sommando i contributi delle singole osservazioni e assume la forma <span class="math display">\[
\ell = \sum_{i=1}^n \sum_{j=1}^m b_j(i)\,\log p_j(i).
\]</span> Massimizzare questa quantità equivale a rendere massima la probabilità assegnata dal modello alle classi effettivamente osservate.</p>
<section id="caso-senza-dipendenza-da-x" class="level3">
<h3 class="anchored" data-anchor-id="caso-senza-dipendenza-da-x">Caso senza dipendenza da <span class="math inline">\(x\)</span></h3>
<p>Se le probabilità non dipendono dall’input, cioè <span class="math inline">\(p_j(i)=P_j\)</span> è costante per tutte le osservazioni, il problema si riduce alla stima dei parametri di una distribuzione categorica. In questo caso la massimizzazione della log-verosimiglianza porta alla stima <span class="math display">\[
\hat P_j = \frac{O_j}{n},
\]</span> dove <span class="math inline">\(O_j\)</span> indica il numero di osservazioni appartenenti alla classe <span class="math inline">\(j\)</span>. La stima coincide quindi con la frequenza empirica, risultato coerente con l’interpretazione probabilistica del modello.</p>
</section>
<section id="caso-con-dipendenza-da-x" class="level3">
<h3 class="anchored" data-anchor-id="caso-con-dipendenza-da-x">Caso con dipendenza da <span class="math inline">\(x\)</span></h3>
<p>Quando la probabilità della classe dipende dall’input <span class="math inline">\(x(i)\)</span>, si introduce un modello parametrico del tipo <span class="math display">\[
p_j(i) = \pi_j(x(i); \alpha,\beta,\gamma),
\]</span> che associa a ciascuna osservazione una distribuzione di probabilità sulle classi. Un esempio fondamentale è fornito dalla <strong>softmax</strong>, definita come <span class="math display">\[
\pi_j(x) = \frac{\exp(\eta_j(x))}{\sum_{k=1}^m \exp(\eta_k(x))},
\qquad
\eta_j(x) = w_j^\top x + c_j.
\]</span> La softmax garantisce automaticamente che le probabilità siano non negative e sommino a uno. In questo contesto, la Cross-Entropy Loss coincide con il negativo della log-verosimiglianza e la stima dei parametri avviene numericamente, tipicamente tramite algoritmi di ottimizzazione iterativa come la discesa del gradiente.</p>
</section>
<section id="cross-entropy-come-funzione-di-perdita" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy-come-funzione-di-perdita">Cross-Entropy come funzione di perdita</h3>
<p>Poiché l’addestramento dei modelli di classificazione avviene tramite <strong>minimizzazione</strong> di una funzione obiettivo, la log-verosimiglianza viene riscritta cambiando segno e normalizzando rispetto al numero di osservazioni. Si ottiene così la <strong>cross-entropy loss</strong>, definita come <span class="math display">\[
\text{loss}_{\text{CE}}(\alpha,\beta,\gamma)
= -\frac{1}{n}\sum_{i=1}^n \sum_{j=1}^m b_j(i)\,\log \pi_j(x(i);\alpha,\beta,\gamma).
\]</span> Questa quantità rappresenta il negativo della log-verosimiglianza media e misura quanto la distribuzione di probabilità predetta dal modello si discosta dalla distribuzione vera, che nel caso di classificazione supervisionata è codificata tramite vettori one-hot.</p>
<p>La stessa espressione può essere interpretata in termini di <strong>entropia incrociata</strong> tra la distribuzione target <span class="math inline">\(b(i)\)</span> e la distribuzione predetta <span class="math inline">\(\pi(x(i))\)</span>. Per una singola osservazione vale <span class="math display">\[
H(b,\pi) = -\sum_{j=1}^m b_j \log \pi_j,
\]</span> e la funzione di perdita complessiva non è altro che la media di questa quantità sul campione: <span class="math display">\[
\text{loss}_{\text{CE}} = \frac{1}{n}\sum_{i=1}^n H\bigl(b(i),\pi(x(i))\bigr).
\]</span></p>
<p>Dal punto di vista interpretativo, minimizzare la cross-entropy equivale a rendere massima la probabilità assegnata dal modello alla classe corretta. L’uso del logaritmo fa sì che predizioni errate ma molto “sicure”, cioè con probabilità alta assegnata alla classe sbagliata, vengano penalizzate in modo particolarmente severo.</p>
<p>Nella pratica computazionale è necessario prestare attenzione alla stabilità numerica. In genere si evita il problema di <span class="math inline">\(\log 0\)</span> introducendo un piccolo termine <span class="math inline">\(\varepsilon\)</span> nelle probabilità oppure lavorando direttamente con formulazioni numericamente stabili della softmax. Inoltre, in presenza di dataset sbilanciati o di rumore nelle etichette, si possono introdurre tecniche come il <em>label smoothing</em> o pesi di classe, che modificano la loss per rendere l’addestramento più robusto.</p>
</section>
</section>
<section id="mean-squared-error-loss-mse" class="level2">
<h2 class="anchored" data-anchor-id="mean-squared-error-loss-mse">Mean Squared Error Loss (MSE)</h2>
<p>La <strong>Mean Squared Error (MSE)</strong> è una funzione di perdita tipicamente utilizzata quando la variabile risposta è quantitativa e si assume un modello <strong>gaussiano</strong> per gli errori. In questo contesto si ipotizza che ciascuna osservazione segua una distribuzione normale <span class="math display">\[
Y(i) \sim \mathcal{N}(\mu(i), \sigma^2(i)),
\]</span> dove <span class="math inline">\(\mu(i)\)</span> rappresenta la media condizionata, eventualmente dipendente dagli input, mentre <span class="math inline">\(\sigma^2(i)\)</span> indica la varianza.</p>
<p>Sotto questa ipotesi, la log-verosimiglianza del campione può essere scritta come <span class="math display">\[
\ell
= \sum_{i=1}^n \left[
-\log \sigma(i)
- \log \sqrt{2\pi}
- \frac{(Y(i)-\mu(i))^2}{2\sigma^2(i)}
\right].
\]</span> Questa espressione mette in evidenza come lo scarto quadratico tra osservazioni e media giochi un ruolo centrale nel modello gaussiano.</p>
<section id="parametri-costanti" class="level3">
<h3 class="anchored" data-anchor-id="parametri-costanti">Parametri costanti</h3>
<p>Nel caso più semplice si assume che <span class="math inline">\(\mu(i)=\mu\)</span> e <span class="math inline">\(\sigma(i)=\sigma\)</span> per ogni osservazione. La massimizzazione della log-verosimiglianza conduce alle stime classiche: la media campionaria come stimatore di <span class="math inline">\(\mu\)</span> e la varianza campionaria con denominatore <span class="math inline">\(n\)</span> come stimatore di <span class="math inline">\(\sigma^2\)</span> nel senso della massima verosimiglianza. In questo scenario la MSE coincide con la varianza empirica attorno alla media stimata.</p>
</section>
<section id="caso-omoschedastico-varianza-costante" class="level3">
<h3 class="anchored" data-anchor-id="caso-omoschedastico-varianza-costante">Caso omoschedastico (varianza costante)</h3>
<p>Un caso fondamentale in regressione è quello in cui la media dipende dagli input <span class="math inline">\(x(i)\)</span>, mentre la varianza è costante, cioè <span class="math inline">\(\sigma^2(i)=\sigma^2\)</span>. Indicando con <span class="math inline">\(\mu(x(i);\alpha,\beta,\gamma)\)</span> un modello parametrico per la media, la parte della log-verosimiglianza che dipende da tali parametri è, a meno di costanti additive e moltiplicative, proporzionale alla somma dei quadrati dei residui. Ne segue che massimizzare la log-verosimiglianza equivale a minimizzare la <strong>MSE</strong>: <span class="math display">\[
\text{loss}_{\text{MSE}}(\alpha,\beta,\gamma)
= \frac{1}{n}\sum_{i=1}^n \bigl(Y(i)-\mu(x(i);\alpha,\beta,\gamma)\bigr)^2.
\]</span></p>
<p>Una volta stimata la media, la stima di massima verosimiglianza della deviazione standard è data da <span class="math display">\[
\hat{\sigma}
= \sqrt{\text{loss}_{\text{MSE}}(\alpha,\beta,\gamma)},
\]</span> mentre la corrispondente stima della varianza risulta <span class="math display">\[
\hat{\sigma}^2_{\text{MLE}}
= \frac{1}{n}\sum_{i=1}^n \bigl(Y(i)-\hat{\mu}(i)\bigr)^2.
\]</span> Dal punto di vista statistico questo stimatore è distorto; lo stimatore <strong>non distorto</strong> della varianza utilizza invece il denominatore <span class="math inline">\(n-p\)</span>, dove <span class="math inline">\(p\)</span> è il numero di parametri stimati nel modello per la media.</p>
</section>
<section id="caso-eteroschedastico-dipendenza-completa-da-x" class="level3">
<h3 class="anchored" data-anchor-id="caso-eteroschedastico-dipendenza-completa-da-x">Caso eteroschedastico (dipendenza completa da <span class="math inline">\(x\)</span>)</h3>
<p>Nel caso più generale anche la varianza dipende dagli input, cioè <span class="math inline">\(\sigma^2(i)=\sigma^2(x(i))\)</span>. In questa situazione la funzione obiettivo coerente con il modello gaussiano è il negativo della log-verosimiglianza: <span class="math display">\[
-\ell(\theta)
= \frac{1}{2}\sum_{i=1}^n \left[
\log\bigl(2\pi \sigma^2(i)\bigr)
+ \frac{(Y(i)-\mu(i))^2}{\sigma^2(i)}
\right].
\]</span> Questo criterio corrisponde a una forma di <strong>weighted least squares</strong>, in cui ciascun residuo è pesato con l’inverso della sua varianza. La stima congiunta dei parametri della media e della varianza non ammette in generale una soluzione in forma chiusa e richiede l’uso di metodi di ottimizzazione iterativi.</p>
</section>
</section>
<section id="regressione-lineare-semplice" class="level2">
<h2 class="anchored" data-anchor-id="regressione-lineare-semplice">Regressione Lineare Semplice</h2>
<p>Nel modello di <strong>regressione lineare semplice</strong> si assume che le variabili indipendenti <span class="math inline">\(x_i\)</span> siano deterministiche, mentre le variabili dipendenti <span class="math inline">\(Y_i\)</span> siano casuali. L’ipotesi di base è che ciascuna osservazione segua un modello gaussiano con media lineare e varianza costante: <span class="math display">\[
Y_i \sim \mathcal{N}(\mu_i, \sigma^2),
\qquad
\mu_i = \beta_0 + \beta_1 x_i.
\]</span> In questa formulazione <span class="math inline">\(\beta_0\)</span> rappresenta l’intercetta del modello, mentre <span class="math inline">\(\beta_1\)</span> quantifica l’effetto medio di una variazione unitaria di <span class="math inline">\(x\)</span> sulla risposta <span class="math inline">\(Y\)</span>.</p>
<p>Assumendo indipendenza delle osservazioni e omoschedasticità, la massimizzazione della log-verosimiglianza gaussiana è equivalente alla minimizzazione della <strong>Mean Squared Error</strong>, definita come <span class="math display">\[
\text{loss}_{\text{MSE}}(\beta_0, \beta_1)
= \frac{1}{n} \sum_{i=1}^n \bigl(Y_i - \beta_0 - \beta_1 x_i\bigr)^2.
\]</span> La stima dei parametri si riduce quindi a un problema di minimi quadrati.</p>
<p>La soluzione analitica di questo problema fornisce le stime di massima verosimiglianza dei coefficienti, che coincidono con le stime dei minimi quadrati ordinari: <span class="math display">\[
\hat{\beta}_1
= \frac{\sum_{i=1}^n x_i Y_i - n \bar{x}\,\bar{Y}}
{\sum_{i=1}^n x_i^2 - n \bar{x}^2},
\qquad
\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{x},
\]</span> dove <span class="math inline">\(\bar{x}\)</span> e <span class="math inline">\(\bar{Y}\)</span> indicano le medie campionarie delle variabili indipendente e dipendente. La stima di <span class="math inline">\(\beta_1\)</span> può essere interpretata come il rapporto tra la covarianza campionaria tra <span class="math inline">\(x\)</span> e <span class="math inline">\(Y\)</span> e la varianza campionaria di <span class="math inline">\(x\)</span>.</p>
<p>Una volta stimati i coefficienti, si procede alla stima della varianza degli errori. Lo stimatore di massima verosimiglianza utilizza il denominatore <span class="math inline">\(n\)</span> ed è quindi distorto. Lo stimatore <strong>non distorto</strong> della varianza degli errori è invece <span class="math display">\[
S_e^2
= \frac{1}{n - 2} \sum_{i=1}^n \bigl(Y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i\bigr)^2,
\]</span> dove il termine <span class="math inline">\(n-2\)</span> rappresenta i gradi di libertà residui dopo la stima dei due parametri <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span>.</p>
</section>
<section id="teorema-di-cochran" class="level2">
<h2 class="anchored" data-anchor-id="teorema-di-cochran">Teorema di Cochran</h2>
<p>Il <strong>teorema di Cochran</strong> fornisce la base teorica per comprendere come la <strong>variabilità totale dei dati</strong> possa essere scomposta in modo rigoroso nei modelli lineari sotto ipotesi gaussiane. L’idea centrale è che, quando le osservazioni seguono una distribuzione normale con <strong>varianza costante</strong> e i parametri vengono stimati all’interno di un modello lineare, la parte dei dati spiegata dal modello e la parte residua possono essere trattate come componenti <strong>indipendenti</strong>, ciascuna con una struttura probabilistica ben definita. Questo risultato giustifica formalmente la scomposizione della varianza utilizzata in regressione lineare, <strong>ANOVA</strong> e <strong>test F</strong>.</p>
<p>Si consideri un vettore aleatorio <span class="math inline">\(X=(X_1,\dots,X_n)\in\mathbb{R}^n\)</span> con componenti indipendenti tali che <span class="math display">\[
X_i \sim \mathcal{N}(\mu_i,\sigma^2),
\]</span> e si assuma che il vettore delle medie <span class="math inline">\(\mu=(\mu_1,\dots,\mu_n)\)</span> appartenga a un sottospazio vettoriale <span class="math inline">\(V\subset\mathbb{R}^n\)</span> di dimensione <span class="math inline">\(k\)</span>. In questo contesto, la stima di massima verosimiglianza di <span class="math inline">\(\mu\)</span> si ottiene come <strong>proiezione ortogonale</strong> del vettore osservato <span class="math inline">\(X\)</span> sul sottospazio <span class="math inline">\(V\)</span>. Indicando con <span class="math inline">\(\pi_V(X)\)</span> tale proiezione, vale <span class="math display">\[
\hat{\mu}=\pi_V(X).
\]</span> Dal punto di vista geometrico, questa stima è quella che minimizza la distanza euclidea tra <span class="math inline">\(X\)</span> e l’insieme dei vettori ammissibili per <span class="math inline">\(\mu\)</span>, coerentemente con il criterio dei minimi quadrati.</p>
<p>La componente di <span class="math inline">\(X\)</span> non spiegata dal modello è il residuo <span class="math inline">\(X-\pi_V(X)\)</span>. La sua norma al quadrato <span class="math display">\[
W=\|X-\pi_V(X)\|^2
\]</span> rappresenta la <strong>somma dei quadrati residui</strong>. Il teorema di Cochran afferma che la quantità <span class="math inline">\(W\)</span> è <strong>indipendente</strong> dalla componente stimata <span class="math inline">\(\pi_V(X)\)</span> e che, normalizzata per la varianza comune <span class="math inline">\(\sigma^2\)</span>, segue una distribuzione chi-quadro con <span class="math inline">\(n-k\)</span> gradi di libertà: <span class="math display">\[
\frac{W}{\sigma^2}\sim\chi^2(n-k).
\]</span></p>
<p>L’indipendenza tra la parte spiegata dal modello e la parte residua, insieme alla distribuzione chi-quadro della somma dei quadrati residui, costituisce il fondamento teorico della <strong>scomposizione della varianza</strong>. È proprio questo risultato che rende possibile confrontare in modo corretto la variabilità spiegata dal modello con quella attribuibile al rumore, utilizzando distribuzioni note e strumenti di inferenza statistica affidabili nei modelli di regressione lineare.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>