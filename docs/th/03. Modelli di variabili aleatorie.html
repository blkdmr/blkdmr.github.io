<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>modelli-di-variabili-aleatorie – IML</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d1aacd23651da4810371d54805babc2f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../th/01. Richiami di probabilità.html">Theory</a></li><li class="breadcrumb-item"><a href="../th/03. Modelli di variabili aleatorie.html">Modelli di variabili aleatorie</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">IML</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/01. Richiami di probabilità.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Richiami di Probabilità</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/02. Variabili aleatorie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Variabili Aleatorie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/03. Modelli di variabili aleatorie.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Modelli di variabili aleatorie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/04. La distribuzione delle statistiche campionarie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La distribuzione delle statistiche campionarie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/05. Stima parametrica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stima parametrica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/06. Verifica delle ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Verifica delle ipotesi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/07. Vettori aleatori.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vettori aleatori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/08. Trasformazione PCA e analisi delle componenti principali.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Trasformazione PCA e analisi delle componenti principali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/09. Funzioni di Perdita e Inferenza Statistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Funzioni di Perdita e Inferenza Statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/10. Ancora sul teorema di Cochran.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ancora sul teorema di Cochran</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/11. Selezione di Variabili e Regolarizzazione nella Regressione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selezione di Variabili e Regolarizzazione nella Regressione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/12. Gestione delle Variabili.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gestione delle Variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/13. Regressione Logistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regressione Logistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/14. Analisi della varianza (ANOVA).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analisi della varianza (ANOVA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/15. ANOVA a due vie (con o senza repliche).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA a due vie (con o senza repliche)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/16. Test del Chi-quadro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Test del Chi-quadro</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Laboratory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/01_02_Introduzione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-02: Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/03_04_Gaussiane.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">03-04: Gaussiane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/05_06_Limite_Centrale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">05-06: Limite Centrale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/07_08_EDA_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">07-08: EDA e PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/09_10_Generazione_campioni.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">09-10: Generazione campioni da distribuzione scelta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/11_12_MLE_Regressione_Abalone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11-12: MLE e Regressione Abalone</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/13_14_Outlier_Regressione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13-14: Outlier e Regressione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/15_16_OLS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15-16: OLS</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Exams</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-01: Analisi distribuzione Dirichlet</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-02: EDA e PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-03: Classificazione Logistic Regression e PyTorch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-04: Regressione con OLS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-05: Minimizzazione con SciPy</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#modelli-di-variabili-aleatorie" id="toc-modelli-di-variabili-aleatorie" class="nav-link active" data-scroll-target="#modelli-di-variabili-aleatorie">Modelli di variabili aleatorie</a>
  <ul class="collapse">
  <li><a href="#variabili-aleatorie-di-bernoulli" id="toc-variabili-aleatorie-di-bernoulli" class="nav-link" data-scroll-target="#variabili-aleatorie-di-bernoulli">Variabili aleatorie di bernoulli</a></li>
  <li><a href="#variabili-aleatorie-binomiali" id="toc-variabili-aleatorie-binomiali" class="nav-link" data-scroll-target="#variabili-aleatorie-binomiali">Variabili aleatorie binomiali</a></li>
  <li><a href="#variabili-aleatorie-di-poisson" id="toc-variabili-aleatorie-di-poisson" class="nav-link" data-scroll-target="#variabili-aleatorie-di-poisson">Variabili aleatorie di poisson</a></li>
  <li><a href="#processi-di-poisson" id="toc-processi-di-poisson" class="nav-link" data-scroll-target="#processi-di-poisson">Processi di poisson</a></li>
  <li><a href="#variabili-aleatorie-uniformi" id="toc-variabili-aleatorie-uniformi" class="nav-link" data-scroll-target="#variabili-aleatorie-uniformi">Variabili aleatorie uniformi</a></li>
  <li><a href="#distribuzione-geometrica" id="toc-distribuzione-geometrica" class="nav-link" data-scroll-target="#distribuzione-geometrica">Distribuzione geometrica</a></li>
  <li><a href="#distribuzione-ipergeometrica" id="toc-distribuzione-ipergeometrica" class="nav-link" data-scroll-target="#distribuzione-ipergeometrica">Distribuzione ipergeometrica</a></li>
  <li><a href="#distribuzione-binomiale-negativa" id="toc-distribuzione-binomiale-negativa" class="nav-link" data-scroll-target="#distribuzione-binomiale-negativa">Distribuzione binomiale negativa</a></li>
  <li><a href="#distribuzione-gamma-poisson" id="toc-distribuzione-gamma-poisson" class="nav-link" data-scroll-target="#distribuzione-gamma-poisson">Distribuzione Gamma-Poisson</a></li>
  <li><a href="#variabili-aleatorie-gaussiane" id="toc-variabili-aleatorie-gaussiane" class="nav-link" data-scroll-target="#variabili-aleatorie-gaussiane">Variabili aleatorie gaussiane</a></li>
  <li><a href="#variabili-aleatorie-beta" id="toc-variabili-aleatorie-beta" class="nav-link" data-scroll-target="#variabili-aleatorie-beta">Variabili aleatorie beta</a></li>
  <li><a href="#variabili-aleatorie-esponenziali" id="toc-variabili-aleatorie-esponenziali" class="nav-link" data-scroll-target="#variabili-aleatorie-esponenziali">Variabili aleatorie esponenziali</a></li>
  <li><a href="#distribuzioni-che-derivano-da-quella-normale" id="toc-distribuzioni-che-derivano-da-quella-normale" class="nav-link" data-scroll-target="#distribuzioni-che-derivano-da-quella-normale">Distribuzioni che derivano da quella normale</a>
  <ul class="collapse">
  <li><a href="#variabili-aleatorie-lognormali" id="toc-variabili-aleatorie-lognormali" class="nav-link" data-scroll-target="#variabili-aleatorie-lognormali">Variabili aleatorie lognormali</a></li>
  <li><a href="#variabili-aleatorie-gamma-chi-quadro-e-erlang" id="toc-variabili-aleatorie-gamma-chi-quadro-e-erlang" class="nav-link" data-scroll-target="#variabili-aleatorie-gamma-chi-quadro-e-erlang">Variabili aleatorie gamma, chi-quadro e erlang</a></li>
  <li><a href="#variabili-aleatorie-t-di-student" id="toc-variabili-aleatorie-t-di-student" class="nav-link" data-scroll-target="#variabili-aleatorie-t-di-student">Variabili aleatorie t di student</a></li>
  <li><a href="#variabili-aleatorie-f-di-fisher" id="toc-variabili-aleatorie-f-di-fisher" class="nav-link" data-scroll-target="#variabili-aleatorie-f-di-fisher">Variabili aleatorie f di fisher</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../th/01. Richiami di probabilità.html">Theory</a></li><li class="breadcrumb-item"><a href="../th/03. Modelli di variabili aleatorie.html">Modelli di variabili aleatorie</a></li></ol></nav></header>




<section id="modelli-di-variabili-aleatorie" class="level1">
<h1>Modelli di variabili aleatorie</h1>
<p>Alcuni tipi di variabili aleatorie compaiono molto frequentemente in natura</p>
<section id="variabili-aleatorie-di-bernoulli" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-di-bernoulli">Variabili aleatorie di bernoulli</h2>
<p>Una variabile aleatoria <span class="math inline">\(X\)</span> si dice di <strong>Bernoulli</strong> se può assumere solo i valori <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>, con probabilità rispettivamente <span class="math inline">\(1 - p\)</span> e <span class="math inline">\(p\)</span>, dove <span class="math inline">\(p \in [0, 1]\)</span>. La sua funzione di massa di probabilità è:</p>
<p><span class="math display">\[
P(X = x) = \begin{cases}
p &amp; \text{se } x = 1, \\
1 - p &amp; \text{se } x = 0.
\end{cases}
\]</span></p>
<p>Il suo <strong>valore atteso</strong> è <span class="math inline">\(E[X] = p\)</span>, mentre la sua <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(X) = p(1 - p)\)</span>.</p>
<p>Un <strong>processo di Bernoulli</strong> è una successione di variabili aleatorie indipendenti <span class="math inline">\(X_i\)</span> con uguale distribuzione di Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span>.</p>
<p>La <strong>distribuzione binomiale</strong> descrive la probabilità del numero di successi in <span class="math inline">\(n\)</span> prove di Bernoulli indipendenti, ovvero della variabile aleatoria:</p>
<p><span class="math display">\[
S_n = X_1 + X_2 + \dots + X_n.
\]</span></p>
</section>
<section id="variabili-aleatorie-binomiali" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-binomiali">Variabili aleatorie binomiali</h2>
<p>Quando si effettuano <span class="math inline">\(n\)</span> ripetizioni <strong>indipendenti</strong> di un esperimento binario, ciascuna con probabilità di successo <span class="math inline">\(p\)</span> e di fallimento <span class="math inline">\(1 - p\)</span>, il numero totale di successi <span class="math inline">\(S_n\)</span> è una variabile aleatoria <strong>binomiale</strong> <span class="math inline">\(\mathcal{B}(n, p)\)</span>.</p>
<p>Il coefficiente binomiale è definito come:</p>
<p><span class="math display">\[
\binom{n}{i} = \dfrac{n!}{i! (n - i)!}.
\]</span></p>
<p>La <strong>funzione di massa di probabilità</strong> di una variabile aleatoria binomiale è:</p>
<p><span class="math display">\[
P(S_n = i) = \binom{n}{i} p^i (1 - p)^{n - i}, \quad \text{per } i = 0, 1, \dots, n.
\]</span></p>
<p>Il suo <strong>valore atteso</strong> è:</p>
<p><span class="math display">\[
E[S_n] = n p,
\]</span></p>
<p>mentre la sua <strong>varianza</strong> è:</p>
<p><span class="math display">\[
\operatorname{Var}(S_n) = n p (1 - p).
\]</span></p>
<p>La figura rappresenta il grafico della funzione di massa di una variabile binomiale con parametri <span class="math inline">\(n = 10\)</span> e <span class="math inline">\(p = 0{,}5\)</span>, che risulta simmetrica rispetto al valore medio.</p>
<p>![[Pasted image 20241103164907 1.png|350]]</p>
</section>
<section id="variabili-aleatorie-di-poisson" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-di-poisson">Variabili aleatorie di poisson</h2>
<p>Una variabile aleatoria <span class="math inline">\(X\)</span> che assume valori interi non negativi <span class="math inline">\(i = 0, 1, 2, \dots\)</span> si dice <strong>di Poisson</strong> di parametro <span class="math inline">\(\lambda &gt; 0\)</span> se la sua funzione di massa di probabilità è:</p>
<p><span class="math display">\[
P(X = i) = \dfrac{e^{-\lambda} \lambda^i}{i!}.
\]</span></p>
<p>Il parametro <span class="math inline">\(\lambda\)</span> rappresenta sia il <strong>valore atteso</strong> <span class="math inline">\(E[X] = \lambda\)</span> sia la <strong>varianza</strong> <span class="math inline">\(\operatorname{Var}(X) = \lambda\)</span>.</p>
<p><strong>Nota.</strong> Le variabili di Poisson vengono spesso utilizzate come approssimazione delle variabili binomiali <span class="math inline">\(\mathcal{B}(n, p)\)</span> quando <span class="math inline">\(n\)</span> è molto grande e <span class="math inline">\(p\)</span> è molto piccolo, mantenendo <span class="math inline">\(\lambda = n p\)</span> costante.</p>
<p>La figura illustra il grafico della funzione di massa di una variabile di Poisson con parametro <span class="math inline">\(\lambda = 4\)</span>.</p>
<p>![[Pasted image 20241103165152 1.png|300]]</p>
<p><strong>Nota.</strong> La distribuzione di Poisson viene spesso utilizzata per modellare il numero di eventi in un intervallo di tempo, dato un tasso medio di occorrenza <span class="math inline">\(\lambda\)</span></p>
</section>
<section id="processi-di-poisson" class="level2">
<h2 class="anchored" data-anchor-id="processi-di-poisson">Processi di poisson</h2>
<p>Un <strong>processo di Poisson</strong> con tasso <span class="math inline">\(\lambda &gt; 0\)</span> descrive il verificarsi di eventi indipendenti nel tempo con un ritmo medio costante. Se <span class="math inline">\(N(t)\)</span> indica il numero di eventi avvenuti nell’intervallo di tempo <span class="math inline">\([0,t]\)</span>, allora <span class="math inline">\(N(t)\)</span> segue una <strong>distribuzione di Poisson</strong> con parametro <span class="math inline">\(\lambda t\)</span>, vale a dire:</p>
<p><span class="math inline">\(P\left(N(t) = k\right) = \dfrac{(\lambda t)^k}{k!}\,e^{-\lambda t}, \quad k = 0,1,2,\ldots\)</span></p>
<p>Il suo <strong>valore atteso</strong> è <span class="math inline">\(E[N(t)] = \lambda t\)</span>, mentre la <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(N(t)) = \lambda t\)</span>. I tempi di attesa fra un evento e il successivo, invece, seguono una <strong>distribuzione esponenziale</strong> con lo stesso parametro <span class="math inline">\(\lambda\)</span>. Uno dei tratti distintivi di questo modello è il suo carattere “senza memoria”, per cui la probabilità di un evento futuro non dipende da quanto tempo è già trascorso.</p>
</section>
<section id="variabili-aleatorie-uniformi" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-uniformi">Variabili aleatorie uniformi</h2>
<p>Una <strong>variabile aleatoria continua</strong> <span class="math inline">\(X\)</span> si dice <strong>uniformemente distribuita</strong> sull’intervallo <span class="math inline">\([a,b]\)</span>(con <span class="math inline">\(a &lt; b\)</span>) se la sua <strong>funzione di densità di probabilità (pdf)</strong> è costante su <span class="math inline">\([a,b]\)</span> e nulla altrove. Formalmente,</p>
<p><span class="math inline">\(f_X(x) = \begin{cases} \dfrac{1}{b - a}, &amp; x \in [a, b],\\ 0, &amp; \text{altrimenti}. \end{cases}\)</span></p>
<p>La distribuzione uniforme è così chiamata perché <strong>ogni valore all’interno dell’intervallo</strong> <span class="math inline">\([a, b]\)</span> è <strong>ugualmente probabile</strong>.</p>
<p>![[Pasted image 20250304113422 1.png|350]]</p>
<p>Il <strong>valore atteso</strong> della variabile è dato da <span class="math inline">\(E[X] = \dfrac{a + b}{2}\)</span>, mentre la <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(X) = \dfrac{(b - a)^2}{12}\)</span>.</p>
<p>Oltre alla versione continua, esiste anche una versione discreta della distribuzione uniforme. Se <span class="math inline">\(X\)</span> può assumere <span class="math inline">\(n\)</span> valori distinti <span class="math inline">\(\{1, 2, \dots, n\}\)</span> con la stessa probabilità, allora la funzione di massa di probabilità è</p>
<p><span class="math inline">\(P(X = k) = \frac{1}{n}, \quad k = 1, 2, \dots, n.\)</span></p>
<p>In questo caso, il valore atteso è <span class="math inline">\(E[X] = \dfrac{n+1}{2}\)</span> e la varianza è <span class="math inline">\(\operatorname{Var}(X) = \dfrac{n^2 - 1}{12}\)</span>.</p>
<p>Questa distribuzione è spesso utilizzata quando si vuole assegnare la stessa probabilità a tutti i possibili valori di una variabile, senza favorirne nessuno.</p>
</section>
<section id="distribuzione-geometrica" class="level2">
<h2 class="anchored" data-anchor-id="distribuzione-geometrica">Distribuzione geometrica</h2>
<p>Una variabile aleatoria <span class="math inline">\(T\)</span> si dice di <strong>distribuzione geometrica</strong>, con parametro <span class="math inline">\(p \in (0,1]\)</span>, se rappresenta il <strong>numero di prove necessarie fino al primo successo</strong> in un processo di Bernoulli, cioè una sequenza di prove indipendenti con probabilità di successo costante <span class="math inline">\(p\)</span>.</p>
<p><strong>Funzione di massa di probabilità (pmf)</strong></p>
<p>Se <span class="math inline">\(T\)</span> rappresenta il numero della prima prova che ha successo, allora:</p>
<p><span class="math display">\[
P(T = k) = (1 - p)^{k - 1} p, \quad \text{per } k = 1, 2, 3, \dots
\]</span></p>
<p>In alternativa, se si considera <span class="math inline">\(Y = T - 1\)</span>, che rappresenta il <strong>numero di fallimenti prima del primo successo</strong>, allora:</p>
<p><span class="math display">\[
P(Y = k) = (1 - p)^k p, \quad \text{per } k = 0, 1, 2, \dots
\]</span></p>
<p><strong>Valore atteso e varianza</strong></p>
<p>Per la variabile <span class="math inline">\(T\)</span> (che inizia da 1):</p>
<p><span class="math display">\[
E[T] = \frac{1}{p}, \quad \operatorname{Var}(T) = \frac{1 - p}{p^2}
\]</span></p>
<p>Per la variabile <span class="math inline">\(Y = T - 1\)</span> (che inizia da 0):</p>
<p><span class="math display">\[
E[Y] = \frac{1 - p}{p}, \quad \operatorname{Var}(Y) = \frac{1 - p}{p^2}
\]</span></p>
<p>La distribuzione geometrica è l’unica distribuzione discreta che gode della <strong>proprietà di assenza di memoria</strong>:</p>
<p><span class="math display">\[
P(T &gt; m + n \mid T &gt; m) = P(T &gt; n), \quad \text{per ogni } m,n \in \mathbb{N}
\]</span></p>
<p>Inoltre, la distribuzione geometrica:</p>
<ul>
<li>È collegata al processo di <strong>Bernoulli</strong>, in cui si eseguono prove ripetute fino al primo successo.</li>
<li>È un caso particolare della <strong>binomiale negativa</strong> con un solo successo.</li>
<li>È l’analogo discreto della <strong>distribuzione esponenziale</strong>, che ha la stessa proprietà di memoria nulla.</li>
</ul>
</section>
<section id="distribuzione-ipergeometrica" class="level2">
<h2 class="anchored" data-anchor-id="distribuzione-ipergeometrica">Distribuzione ipergeometrica</h2>
<p>La variabile aleatoria <span class="math inline">\(X\)</span> segue una <strong>distribuzione ipergeometrica</strong> se rappresenta il numero di successi ottenuti estraendo <strong>senza reinserimento</strong> da una popolazione finita composta da successi e insuccessi.</p>
<p>Supponiamo di avere: - una popolazione di dimensione <span class="math inline">\(N\)</span>, - che contiene <span class="math inline">\(K\)</span> elementi di tipo “successo” (e quindi <span class="math inline">\(N - K\)</span> di tipo “insuccesso”), - da cui si estraggono <span class="math inline">\(n\)</span> elementi <strong>senza reinserimento</strong>,</p>
<p>allora <span class="math inline">\(X\)</span> è il numero di successi nelle <span class="math inline">\(n\)</span> estrazioni.</p>
<p><strong>Funzione di massa di probabilità (pmf)</strong></p>
<p><span class="math display">\[
P(X = k) = \frac{\binom{K}{k} \binom{N - K}{n - k}}{\binom{N}{n}}
\]</span></p>
<p>dove</p>
<p><span class="math display">\[
\max(0,\; n - (N - K)) \le k \le \min(K,\; n)
\]</span></p>
<p><strong>Valore atteso e varianza</strong></p>
<p><span class="math display">\[
E[X] = n \cdot \frac{K}{N}
\]</span></p>
<p><span class="math display">\[
\operatorname{Var}(X) = n \cdot \frac{K}{N} \cdot \left(1 - \frac{K}{N}\right) \cdot \frac{N - n}{N - 1}
\]</span></p>
<p>A differenza della distribuzione binomiale:</p>
<ul>
<li>Nella <strong>binomiale</strong> le prove sono indipendenti (estrazione con reinserimento).</li>
<li>Nella <strong>ipergeometrica</strong> le estrazioni sono <strong>senza reinserimento</strong>, quindi <strong>dipendenti</strong>.</li>
<li>Se <span class="math inline">\(N\)</span> è molto grande rispetto a <span class="math inline">\(n\)</span>, l’ipergometrica si approssima alla binomiale con <span class="math inline">\(p = \frac{K}{N}\)</span>.</li>
</ul>
</section>
<section id="distribuzione-binomiale-negativa" class="level2">
<h2 class="anchored" data-anchor-id="distribuzione-binomiale-negativa">Distribuzione binomiale negativa</h2>
<p>Una variabile aleatoria <span class="math inline">\(X\)</span> si dice di <strong>binomiale negativa</strong> se rappresenta il numero di fallimenti prima di ottenere <span class="math inline">\(r\)</span> successi in una sequenza di prove di Bernoulli indipendenti, ciascuna con probabilità di successo <span class="math inline">\(p \in (0, 1]\)</span>. Si indica con:</p>
<p><span class="math display">\[
X \sim \operatorname{NB}(r, p)
\]</span></p>
<p>Il supporto di <span class="math inline">\(X\)</span> è l’insieme <span class="math inline">\(\{0, 1, 2, \dots\}\)</span>.</p>
<p>La <strong>funzione di massa di probabilità</strong> è:</p>
<p><span class="math display">\[
P(X = k) = \binom{k + r - 1}{r - 1} p^r (1 - p)^k, \quad k = 0, 1, 2, \dots
\]</span></p>
<p>dove: - <span class="math inline">\(k\)</span> è il numero di fallimenti, - <span class="math inline">\(r\)</span> è il numero di successi desiderati.</p>
<p>Il <strong>valore atteso</strong> è:</p>
<p><span class="math display">\[
E[X] = \frac{r(1 - p)}{p}
\]</span></p>
<p>La <strong>varianza</strong> è:</p>
<p><span class="math display">\[
\operatorname{Var}(X) = \frac{r(1 - p)}{p^2}
\]</span></p>
<p>La distribuzione geometrica è un caso particolare della binomiale negativa con <span class="math inline">\(r = 1\)</span>.</p>
<p><strong>Interpretazione alternativa</strong></p>
<p>In alcuni contesti si considera una variabile <span class="math inline">\(Y = X + r\)</span>, che rappresenta il <strong>numero totale di prove</strong> necessarie per ottenere <span class="math inline">\(r\)</span> successi. In tal caso, la funzione di massa è:</p>
<p><span class="math display">\[
P(Y = n) = \binom{n - 1}{r - 1} p^r (1 - p)^{n - r}, \quad n = r, r + 1, r + 2, \dots
\]</span></p>
<p>Il valore atteso e la varianza di <span class="math inline">\(Y\)</span> sono:</p>
<p><span class="math display">\[
E[Y] = \frac{r}{p}, \qquad \operatorname{Var}(Y) = \frac{r(1 - p)}{p^2}
\]</span></p>
</section>
<section id="distribuzione-gamma-poisson" class="level2">
<h2 class="anchored" data-anchor-id="distribuzione-gamma-poisson">Distribuzione Gamma-Poisson</h2>
<p>La distribuzione <strong>Gamma-Poisson</strong> è una <strong>mistura</strong> tra una distribuzione di Poisson e una distribuzione Gamma. Si ottiene considerando che il parametro <span class="math inline">\(\lambda\)</span> della Poisson <strong>non è fisso</strong>, ma segue una distribuzione Gamma.</p>
<p>Formalmente, si definisce una variabile aleatoria <span class="math inline">\(X\)</span> come:</p>
<p><span class="math display">\[
X \mid \lambda \sim \operatorname{Poisson}(\lambda), \quad \lambda \sim \operatorname{Gamma}(r, \theta)
\]</span></p>
<p>dove: - <span class="math inline">\(r &gt; 0\)</span> è il parametro di forma della Gamma, - <span class="math inline">\(\theta &gt; 0\)</span> è il parametro di scala della Gamma (oppure <span class="math inline">\(\beta = 1/\theta\)</span> se si usa la parametrizzazione alternativa con il parametro di tasso).</p>
<p><strong>Distribuzione marginale di <span class="math inline">\(X\)</span></strong></p>
<p>Integrando su <span class="math inline">\(\lambda\)</span>, la distribuzione marginale di <span class="math inline">\(X\)</span> è la <strong>binomiale negativa</strong>:</p>
<p><span class="math display">\[
X \sim \operatorname{NB}(r, p), \quad \text{con } p = \frac{\theta}{1 + \theta}
\]</span></p>
<p>oppure, invertendo la formula:</p>
<p><span class="math display">\[
\theta = \frac{p}{1 - p}
\]</span></p>
<p>La <strong>funzione di massa di probabilità</strong> della distribuzione marginale è:</p>
<p><span class="math display">\[
P(X = k) = \binom{k + r - 1}{k} \left( \frac{\theta}{1 + \theta} \right)^r \left( \frac{1}{1 + \theta} \right)^k, \quad k = 0, 1, 2, \dots
\]</span></p>
<p>oppure, in termini di <span class="math inline">\(p\)</span>:</p>
<p><span class="math display">\[
P(X = k) = \binom{k + r - 1}{k} (1 - p)^r p^k
\]</span></p>
<p>Il <strong>valore atteso</strong> di <span class="math inline">\(X\)</span> è:</p>
<p><span class="math display">\[
E[X] = r \cdot \theta
\]</span></p>
<p>La <strong>varianza</strong> è:</p>
<p><span class="math display">\[
\operatorname{Var}(X) = r \cdot \theta (1 + \theta)
\]</span></p>
<p>oppure, usando <span class="math inline">\(p = \theta / (1 + \theta)\)</span>:</p>
<p><span class="math display">\[
E[X] = \frac{r(1 - p)}{p}, \qquad \operatorname{Var}(X) = \frac{r(1 - p)}{p^2}
\]</span></p>
<p>La Gamma-Poisson modella <strong>conteggi</strong> dove il tasso <span class="math inline">\(\lambda\)</span> non è fisso ma <strong>casuale</strong>, diverso da soggetto a soggetto:</p>
<p><span class="math display">\[
\lambda \sim \operatorname{Gamma}(r, \theta), \quad X \mid \lambda \sim \operatorname{Poisson}(\lambda)
\]</span></p>
<p>Questa <strong>eterogeneità</strong> tra unità spiega perché:</p>
<ul>
<li>la <strong>media</strong> è <span class="math inline">\(E[X] = r\theta\)</span>,</li>
<li>ma la <strong>varianza</strong> è più grande: <span class="math inline">\(\operatorname{Var}(X) = r\theta(1 + \theta)\)</span>.</li>
</ul>
<p>La Poisson ha <span class="math inline">\(\operatorname{Var}(X) = E[X]\)</span> (dispersione fissa), mentre qui si ha <strong>sovradispersione</strong> dovuta alla variabilità di <span class="math inline">\(\lambda\)</span>.</p>
</section>
<section id="variabili-aleatorie-gaussiane" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-gaussiane">Variabili aleatorie gaussiane</h2>
<p>Una variabile aleatoria <span class="math inline">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span> si dice <strong>gaussiana</strong> (o <strong>normale</strong>) di parametri <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma^2\)</span> se ha la seguente funzione di densità di probabilità:</p>
<p><span class="math display">\[
f(x) = \dfrac{1}{\sqrt{2\pi \sigma^2}} \exp\left( -\dfrac{(x - \mu)^2}{2\sigma^2} \right).
\]</span></p>
<p>La funzione di densità è una curva a campana, detta <strong>curva di Gauss</strong>, simmetrica rispetto a <span class="math inline">\(x = \mu\)</span>, con massimo in <span class="math inline">\(x = \mu\)</span> di altezza <span class="math inline">\((\sigma \sqrt{2\pi})^{-1} \approx 0{,}399/\sigma\)</span>.</p>
<p>Il <strong>valore atteso</strong> è <span class="math inline">\(E[X] = \mu\)</span>, mentre la <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(X) = \sigma^2\)</span>.</p>
<p><strong>Nota.</strong> Il momento secondo è <span class="math inline">\(E[X^2] = \sigma^2 + \mu^2\)</span>.</p>
<p><strong>Proposizione.</strong> Se <span class="math inline">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span> e <span class="math inline">\(Y = \alpha X + \beta\)</span> con <span class="math inline">\(\alpha \neq 0\)</span>, allora <span class="math inline">\(Y \sim \mathcal{N}(\alpha \mu + \beta, \alpha^2 \sigma^2)\)</span>.</p>
<p>La variabile standardizzata:</p>
<p><span class="math display">\[
Z = \dfrac{X - \mu}{\sigma}
\]</span></p>
<p>segue una distribuzione <strong>normale standard</strong> <span class="math inline">\(\mathcal{N}(0, 1)\)</span>.</p>
<p>Il grafico della funzione di densità di una normale standard mostra la classica forma a campana centrata in zero.</p>
<p>![[Pasted image 20241103170100 1.png|300]]</p>
<p>La <strong>funzione di ripartizione</strong> della normale standard è indicata con <span class="math inline">\(\Phi\)</span> ed è definita come:</p>
<p><span class="math display">\[
\Phi(x) = P(Z \leq x) = \dfrac{1}{\sqrt{2\pi}} \int_{-\infty}^{x} e^{-y^2/2} \, dy.
\]</span></p>
<p>Poiché <span class="math inline">\(Z = \dfrac{X - \mu}{\sigma}\)</span>, possiamo esprimere le probabilità relative a <span class="math inline">\(X\)</span> in termini di <span class="math inline">\(\Phi\)</span>:</p>
<p><span class="math display">\[
P(X &lt; b) = \Phi\left( \dfrac{b - \mu}{\sigma} \right).
\]</span></p>
<p>Per <span class="math inline">\(a &lt; b\)</span>:</p>
<p><span class="math display">\[
P(a &lt; X &lt; b) = \Phi\left( \dfrac{b - \mu}{\sigma} \right) - \Phi\left( \dfrac{a - \mu}{\sigma} \right).
\]</span></p>
<p>L’integrale che definisce <span class="math inline">\(\Phi(x)\)</span> non ha una soluzione analitica esatta; si utilizzano tabelle o approssimazioni numeriche.</p>
<p>![[Pasted image 20241107114743 1.png|500]]</p>
<p>Poiché la normale standard è simmetrica rispetto a zero:</p>
<p><span class="math display">\[
\Phi(-x) = 1 - \Phi(x).
\]</span></p>
<p>Per ogni <span class="math inline">\(\alpha \in (0, 1)\)</span>, definiamo <span class="math inline">\(z_\alpha\)</span> come:</p>
<p><span class="math display">\[
P(Z &gt; z_\alpha) = \alpha \quad \Rightarrow \quad z_\alpha = \Phi^{-1}(1 - \alpha).
\]</span></p>
<p>Il <strong>quantile</strong> <span class="math inline">\(k\)</span>-esimo della normale standard è il valore <span class="math inline">\(m\)</span> tale che:</p>
<p><span class="math display">\[
\Phi(m) = \dfrac{k}{100}.
\]</span></p>
<p>Ponendo <span class="math inline">\(k = 100(1 - \alpha)\)</span>, otteniamo <span class="math inline">\(z_\alpha\)</span>, indicando che la normale standard è inferiore a <span class="math inline">\(z_\alpha\)</span> nel <span class="math inline">\(k\%\)</span> dei casi.</p>
</section>
<section id="variabili-aleatorie-beta" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-beta">Variabili aleatorie beta</h2>
<p>Le variabili aleatorie <strong>beta</strong> sono distribuite secondo la <strong>distribuzione beta</strong>, una distribuzione continua definita su un intervallo <span class="math inline">\([0,1]\)</span> e caratterizzata da due parametri positivi <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>. La funzione di densità di probabilità (pdf) della distribuzione beta è data da:</p>
<p><span class="math inline">\(f_X(x) = \dfrac{x^{\alpha - 1} (1 - x)^{\beta - 1}}{B(\alpha, \beta)}, \quad 0 \leq x \leq 1,\)</span></p>
<p>dove il denominatore è la <strong>funzione beta</strong>, definita come:</p>
<p><span class="math inline">\(B(\alpha, \beta) = \int_0^1 t^{\alpha - 1} (1 - t)^{\beta - 1} dt\)</span></p>
<p>Questa funzione normalizza la densità affinché l’area totale sotto la curva sia uguale a <span class="math inline">\(1\)</span>.</p>
<p>Il valore atteso della distribuzione Beta è dato da:</p>
<p><span class="math inline">\(E[X] = \dfrac{\alpha}{\alpha + \beta}\)</span></p>
<p>La varianza è:</p>
<p><span class="math inline">\(\operatorname{Var}(X) = \dfrac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}\)</span></p>
<p>La distribuzione Beta è molto flessibile perché, in base ai valori di <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>, può assumere forme molto diverse.</p>
<p>![[Pasted image 20250304115356 1.png|350]]</p>
<p>Per esempio, se <span class="math inline">\(\alpha = \beta = 1\)</span>, la distribuzione diventa uniforme su <span class="math inline">\([0,1]\)</span>. Se <span class="math inline">\(\alpha &gt; 1\)</span> e <span class="math inline">\(\beta &gt; 1\)</span>, la distribuzione è concentrata al centro. Se invece uno dei due parametri è minore di <span class="math inline">\(1\)</span>, la distribuzione diventa asimmetrica, con una maggiore probabilità vicino a <span class="math inline">\(0\)</span> o <span class="math inline">\(1\)</span>.</p>
</section>
<section id="variabili-aleatorie-esponenziali" class="level2">
<h2 class="anchored" data-anchor-id="variabili-aleatorie-esponenziali">Variabili aleatorie esponenziali</h2>
<p>Una variabile aleatoria continua <span class="math inline">\(X\)</span> si dice <strong>esponenziale</strong> con parametro <span class="math inline">\(\lambda &gt; 0\)</span> se la sua funzione di densità di probabilità è:</p>
<p><span class="math display">\[
f(x) = \begin{cases}
\lambda e^{-\lambda x} &amp; \text{se } x \geq 0, \\
0 &amp; \text{se } x &lt; 0.
\end{cases}
\]</span></p>
<p>La <strong>funzione di ripartizione</strong> è:</p>
<p><span class="math display">\[
F(x) = P(X \leq x) = \begin{cases}
1 - e^{-\lambda x} &amp; \text{se } x \geq 0, \\
0 &amp; \text{se } x &lt; 0.
\end{cases}
\]</span></p>
<p>La distribuzione esponenziale modella tipicamente il <strong>tempo di attesa</strong> prima che si verifichi un evento casuale. Il suo <strong>valore atteso</strong> è:</p>
<p><span class="math display">\[
E[X] = \dfrac{1}{\lambda},
\]</span></p>
<p>il <strong>momento secondo</strong> è:</p>
<p><span class="math display">\[
E[X^2] = \dfrac{2}{\lambda^2},
\]</span></p>
<p>e la <strong>varianza</strong> è:</p>
<p><span class="math display">\[
\operatorname{Var}(X) = \dfrac{1}{\lambda^2}.
\]</span></p>
<p>La proprietà fondamentale è l’<strong>assenza di memoria</strong>:</p>
<p><span class="math display">\[
P(X &gt; s + t \mid X &gt; t) = P(X &gt; s), \quad \forall s, t \geq 0.
\]</span></p>
<p><strong>Esempio.</strong> Se <span class="math inline">\(X\)</span> rappresenta il tempo di vita di un oggetto, sapendo che ha già funzionato per un tempo <span class="math inline">\(t\)</span>, la probabilità che continui a funzionare per un ulteriore tempo <span class="math inline">\(s\)</span> è la stessa che avrebbe avuto all’inizio.</p>
<p>Per la distribuzione esponenziale, vale:</p>
<p><span class="math display">\[
P(X &gt; s + t) = P(X &gt; s) P(X &gt; t).
\]</span></p>
<p>Questo riflette la proprietà di assenza di memoria, poiché la probabilità che l’evento non si sia verificato entro <span class="math inline">\(s + t\)</span> è il prodotto delle probabilità di non verificarsi in <span class="math inline">\(s\)</span> e <span class="math inline">\(t\)</span>.</p>
</section>
<section id="distribuzioni-che-derivano-da-quella-normale" class="level2">
<h2 class="anchored" data-anchor-id="distribuzioni-che-derivano-da-quella-normale">Distribuzioni che derivano da quella normale</h2>
<section id="variabili-aleatorie-lognormali" class="level3">
<h3 class="anchored" data-anchor-id="variabili-aleatorie-lognormali">Variabili aleatorie lognormali</h3>
<p>Una variabile aleatoria <span class="math inline">\(Y\)</span> si dice di <strong>distribuzione lognormale</strong> se la variabile <span class="math inline">\(\ln(Y)\)</span> segue una distribuzione normale con parametri <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma^2\)</span>. In altre parole, se <span class="math inline">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span>, allora <span class="math inline">\(Y = e^X\)</span> si dice lognormale. La <strong>funzione di densità</strong> di probabilità di <span class="math inline">\(Y\)</span>, per <span class="math inline">\(y &gt; 0\)</span>, è data da</p>
<p><span class="math inline">\(f_Y(y) = \dfrac{1}{y\,\sigma \sqrt{2\pi}} \exp\!\left(-\dfrac{(\ln(y) - \mu)^2}{2\sigma^2}\right)\)</span></p>
<p>![[Pasted image 20250302200445 1.png]]</p>
<p>Il suo <strong>valore atteso</strong> si calcola come <span class="math inline">\(E[Y] = e^{\mu + \frac{\sigma^2}{2}}\)</span>, mentre la sua <strong>varianza</strong> risulta <span class="math inline">\(\operatorname{Var}(Y) = \left(e^{\sigma^2} - 1\right)\,e^{2\mu + \sigma^2}\)</span></p>
</section>
<section id="variabili-aleatorie-gamma-chi-quadro-e-erlang" class="level3">
<h3 class="anchored" data-anchor-id="variabili-aleatorie-gamma-chi-quadro-e-erlang">Variabili aleatorie gamma, chi-quadro e erlang</h3>
<p>La <strong>distribuzione Gamma</strong> caratterizza una variabile aleatoria definita per valori positivi ed è spesso parametrizzata con un parametro di forma <span class="math inline">\(\alpha\)</span> e un parametro di tasso <span class="math inline">\(\beta\)</span>. In questo caso, la <strong>funzione di densità</strong> di probabilità, per <span class="math inline">\(x &gt; 0\)</span>, è</p>
<p><span class="math display">\[f_X(x) = \dfrac{\beta^\alpha}{\Gamma(\alpha)}\, x^{\alpha - 1} e^{-\beta x}\]</span> Il suo <strong>valore atteso</strong> è <span class="math inline">\(E[X] = \dfrac{\alpha}{\beta}\)</span>, mentre la sua <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(X) = \dfrac{\alpha}{\beta^2}\)</span>. Questa distribuzione è utile per descrivere tempi di attesa fino al verificarsi di un certo numero di eventi in processi di Poisson e, in generale, per modellare fenomeni positivi con variabilità asimmetrica.</p>
<p><strong>Nota.</strong> Talvolta, la distribuzione Gamma è espressa in funzione dei parametri <span class="math inline">\(k\)</span> e <span class="math inline">\(\theta\)</span>, dove <span class="math inline">\(\displaystyle \alpha =k\)</span> e <span class="math inline">\(\displaystyle \beta =1/\theta\)</span>.</p>
<p>![[Pasted image 20250302203805 1.png]]</p>
<p>La <strong>distribuzione <span class="math inline">\(\chi^2\)</span> (chi-quadro)</strong> è un caso particolare della gamma in cui <span class="math inline">\(\alpha = \dfrac{k}{2}\)</span> e <span class="math inline">\(\beta = \dfrac{1}{2}\)</span>, dove <span class="math inline">\(k\)</span> rappresenta i gradi di libertà. In tale situazione, la funzione di densità risulta</p>
<p><span class="math inline">\(\displaystyle f_X(x) = \frac{1}{2^{k/2}\,\Gamma(\dfrac{k}{2})} \, x^{({k}/{2}) - 1} e^{-{x}/{2}}\)</span></p>
<p>per <span class="math inline">\(x&gt;0\)</span>. Il suo <strong>valore atteso</strong> è <span class="math inline">\(E[X] = k\)</span>, la <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(X) = 2k\)</span>. Questa distribuzione è fondamentale in statistica per definire test di ipotesi e intervalli di confidenza relativi, ad esempio, a varianze e regressioni.</p>
<p>![[Pasted image 20250302203827 1.png]]</p>
<p>La <strong>distribuzione Erlang</strong> è anch’essa un caso speciale di gamma in cui il parametro di forma <span class="math inline">\(\alpha\)</span> è un intero positivo <span class="math inline">\(k\)</span>. Con un parametro di tasso <span class="math inline">\(\lambda\)</span>, la funzione di densità si esprime come</p>
<p><span class="math inline">\(\displaystyle f_X(x) = \dfrac{\lambda^k}{(k-1)!}\, x^{k-1}\, e^{-\lambda x}\)</span></p>
<p>per <span class="math inline">\(x&gt;0\)</span>. Il suo <strong>valore atteso</strong> è <span class="math inline">\(E[X] = \frac{k}{\lambda}\)</span>, mentre la <strong>varianza</strong> è <span class="math inline">\(\operatorname{Var}(X) = \dfrac{k}{\lambda^2}\)</span>. Si ottiene come somma di <span class="math inline">\(k\)</span> variabili esponenziali indipendenti, tutte con lo stesso parametro <span class="math inline">\(\lambda\)</span>, ed è comunemente impiegata per analizzare tempi di attesa in processi di natura “conta-eventi” (processi di Poisson).</p>
<p>![[Pasted image 20250302204541 1.png]]</p>
</section>
<section id="variabili-aleatorie-t-di-student" class="level3">
<h3 class="anchored" data-anchor-id="variabili-aleatorie-t-di-student">Variabili aleatorie t di student</h3>
<p>La distribuzione <strong>t di Student</strong> è una distribuzione di probabilità continua utilizzata principalmente nelle inferenze statistiche, in particolare nei test di ipotesi per campioni di dimensioni ridotte. È caratterizzata da un parametro detto <strong>gradi di libertà</strong> (<span class="math inline">\(\nu\)</span>), che influisce sulla forma della distribuzione.</p>
<p>La funzione di densità di probabilità (pdf) della distribuzione t di Student è</p>
<p><span class="math inline">\(f_X(x) = \dfrac{\Gamma\left(\dfrac{\nu+1}{2}\right)}{\sqrt{\nu \pi}\ \Gamma\left(\dfrac{\nu}{2}\right)} \left(1 + \dfrac{x^2}{\nu} \right)^{-\dfrac{\nu+1}{2}}, \quad -\infty &lt; x &lt; \infty.\)</span></p>
<p>Qui, <span class="math inline">\(\Gamma(\cdot)\)</span> rappresenta la funzione Gamma.</p>
<p>![[Pasted image 20250307155750 1.png]]</p>
<p>La distribuzione t di Student ha media:</p>
<p><span class="math inline">\(E[X] = 0, \quad \text{per } \nu &gt; 1.\)</span></p>
<p>La varianza è:</p>
<p><span class="math inline">\(\operatorname{Var}(X) = \dfrac{\nu}{\nu - 2}, \quad \text{per } \nu &gt; 2.\)</span></p>
<p>Per <span class="math inline">\(\nu \leq 2\)</span>, la varianza non è definita, mentre per <span class="math inline">\(\nu \leq 1\)</span>, la media non è definita.</p>
<p>La distribuzione t di Student assomiglia alla distribuzione normale standard, ma ha <strong>code più pesanti</strong>, il che significa che assegna una maggiore probabilità a valori estremi. Questo comportamento è particolarmente utile quando si lavora con campioni di piccole dimensioni, dove la distribuzione dei dati potrebbe non essere perfettamente normale.</p>
<p>Un’applicazione fondamentale della distribuzione t di Student è nel <strong>test t di Student</strong>, che viene utilizzato per confrontare la media di un campione con un valore noto o per confrontare le medie di due campioni. In generale, quando la dimensione del campione è grande (<span class="math inline">\(\nu \to \infty\)</span>), la distribuzione t di Student si avvicina alla distribuzione normale standard.</p>
<p>Questa distribuzione è molto utilizzata in statistica inferenziale per stimare intervalli di confidenza e per test di significatività quando la varianza della popolazione non è nota.</p>
</section>
<section id="variabili-aleatorie-f-di-fisher" class="level3">
<h3 class="anchored" data-anchor-id="variabili-aleatorie-f-di-fisher">Variabili aleatorie f di fisher</h3>
<p>La distribuzione <strong>F di Fisher</strong> è una distribuzione di probabilità continua utilizzata principalmente nei test di ipotesi statistici per confrontare le varianze di due popolazioni. È particolarmente importante nell’<strong>analisi della varianza (ANOVA)</strong> e nei <strong>test F</strong>, che servono a determinare se due campioni provengono da popolazioni con la stessa varianza.</p>
<p>La distribuzione F di Fisher dipende da due parametri, detti <strong>gradi di libertà</strong>: <span class="math inline">\(d_1\)</span> per il numeratore e <span class="math inline">\(d_2\)</span> per il denominatore. La funzione di densità di probabilità (pdf) è:</p>
<p><span class="math inline">\(f_X(x) = \dfrac{\left(\dfrac{d_1}{d_2}\right)^{\dfrac{d_1}{2}} x^{\dfrac{d_1}{2} - 1}}{B\left(\dfrac{d_1}{2}, \dfrac{d_2}{2}\right)} \left(1 + \dfrac{d_1}{d_2} x\right)^{-\dfrac{d_1 + d_2}{2}}, \quad x &gt; 0.\)</span></p>
<p>dove <span class="math inline">\(B(a, b)\)</span> è la funzione Beta.</p>
<p>![[Pasted image 20250307155915 1.png]]</p>
<p>La distribuzione F è sempre definita per valori positivi <span class="math inline">\(x &gt; 0\)</span>, perché rappresenta il rapporto tra due varianze stimate da campioni casuali. Il <strong>valore atteso</strong> della distribuzione è dato da:</p>
<p><span class="math inline">\(E[X] = \dfrac{d_2}{d_2 - 2}, \quad \text{per } d_2 &gt; 2\)</span></p>
<p>La <strong>varianza</strong> è</p>
<p><span class="math inline">\(\operatorname{Var}(X) = \dfrac{2 d_2^2 (d_1 + d_2 - 2)}{d_1 (d_2 - 2)^2 (d_2 - 4)}, \quad \text{per } d_2 &gt; 4\)</span></p>
<p>Se <span class="math inline">\(d_2 \leq 2\)</span>, la media non è definita, mentre se <span class="math inline">\(d_2 \leq 4\)</span>, la varianza non è definita.</p>
<p>La distribuzione F di Fisher è ottenuta come il rapporto tra due variabili aleatorie <strong>chi-quadrato indipendenti</strong>, normalizzate rispetto ai rispettivi gradi di libertà:</p>
<p><span class="math inline">\(F = {\dfrac{S_1^2}{d_1}}/{\dfrac{S_2^2}{d_2}}.\)</span></p>
<p>dove <span class="math inline">\(S_1^2\)</span> e <span class="math inline">\(S_2^2\)</span> sono varianze campionarie.</p>
<p>La distribuzione F è <strong>asimmetrica e sempre positiva</strong>, con una coda più lunga a destra. Man mano che i gradi di libertà aumentano, la distribuzione si avvicina a una distribuzione normale.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>