<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>selezione-di-variabili-e-regolarizzazione-nella-regressione – IML</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d1aacd23651da4810371d54805babc2f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../th/01. Richiami di probabilità.html">Theory</a></li><li class="breadcrumb-item"><a href="../th/11. Selezione di Variabili e Regolarizzazione nella Regressione.html">Selezione di Variabili e Regolarizzazione nella Regressione</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">IML</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/01. Richiami di probabilità.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Richiami di Probabilità</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/02. Variabili aleatorie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Variabili Aleatorie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/03. Modelli di variabili aleatorie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modelli di variabili aleatorie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/04. La distribuzione delle statistiche campionarie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La distribuzione delle statistiche campionarie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/05. Stima parametrica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stima parametrica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/06. Verifica delle ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Verifica delle ipotesi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/07. Vettori aleatori.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vettori aleatori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/08. Trasformazione PCA e analisi delle componenti principali.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Trasformazione PCA e analisi delle componenti principali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/09. Funzioni di Perdita e Inferenza Statistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Funzioni di Perdita e Inferenza Statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/10. Ancora sul teorema di Cochran.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ancora sul teorema di Cochran</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/11. Selezione di Variabili e Regolarizzazione nella Regressione.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Selezione di Variabili e Regolarizzazione nella Regressione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/12. Gestione delle Variabili.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gestione delle Variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/13. Regressione Logistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regressione Logistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/14. Analisi della varianza (ANOVA).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analisi della varianza (ANOVA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/15. ANOVA a due vie (con o senza repliche).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA a due vie (con o senza repliche)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../th/16. Test del Chi-quadro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Test del Chi-quadro</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Laboratory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/01_02_Introduzione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-02: Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/03_04_Gaussiane.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">03-04: Gaussiane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/05_06_Limite_Centrale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">05-06: Limite Centrale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/07_08_EDA_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">07-08: EDA e PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/09_10_Generazione_campioni.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">09-10: Generazione campioni da distribuzione scelta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/11_12_MLE_Regressione_Abalone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11-12: MLE e Regressione Abalone</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/13_14_Outlier_Regressione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13-14: Outlier e Regressione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lab/15_16_OLS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15-16: OLS</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Exams</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-01: Analisi distribuzione Dirichlet</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-02: EDA e PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-03: Classificazione Logistic Regression e PyTorch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-04: Regressione con OLS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exams/esame_1_5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01-05: Minimizzazione con SciPy</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#selezione-di-variabili-e-regolarizzazione-nella-regressione" id="toc-selezione-di-variabili-e-regolarizzazione-nella-regressione" class="nav-link active" data-scroll-target="#selezione-di-variabili-e-regolarizzazione-nella-regressione">Selezione di Variabili e Regolarizzazione nella Regressione</a>
  <ul class="collapse">
  <li><a href="#metodi-stepwise" id="toc-metodi-stepwise" class="nav-link" data-scroll-target="#metodi-stepwise">Metodi Stepwise</a>
  <ul class="collapse">
  <li><a href="#metodo-backward" id="toc-metodo-backward" class="nav-link" data-scroll-target="#metodo-backward">Metodo Backward</a></li>
  <li><a href="#metodo-forward" id="toc-metodo-forward" class="nav-link" data-scroll-target="#metodo-forward">Metodo Forward</a></li>
  </ul></li>
  <li><a href="#metodi-globali" id="toc-metodi-globali" class="nav-link" data-scroll-target="#metodi-globali">Metodi Globali</a></li>
  <li><a href="#coefficienti-di-determinazione" id="toc-coefficienti-di-determinazione" class="nav-link" data-scroll-target="#coefficienti-di-determinazione">Coefficienti di Determinazione</a>
  <ul class="collapse">
  <li><a href="#r2" id="toc-r2" class="nav-link" data-scroll-target="#r2"><span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#r_a2" id="toc-r_a2" class="nav-link" data-scroll-target="#r_a2"><span class="math inline">\(R_a^2\)</span></a></li>
  </ul></li>
  <li><a href="#overfitting" id="toc-overfitting" class="nav-link" data-scroll-target="#overfitting">Overfitting</a></li>
  <li><a href="#validazione" id="toc-validazione" class="nav-link" data-scroll-target="#validazione">Validazione</a></li>
  <li><a href="#regolarizzazione" id="toc-regolarizzazione" class="nav-link" data-scroll-target="#regolarizzazione">Regolarizzazione</a>
  <ul class="collapse">
  <li><a href="#ridge-regression-penalizzazione-l2" id="toc-ridge-regression-penalizzazione-l2" class="nav-link" data-scroll-target="#ridge-regression-penalizzazione-l2">Ridge Regression (penalizzazione L2)</a></li>
  <li><a href="#lasso-regression-penalizzazione-l1" id="toc-lasso-regression-penalizzazione-l1" class="nav-link" data-scroll-target="#lasso-regression-penalizzazione-l1">Lasso Regression (penalizzazione L1)</a></li>
  <li><a href="#elastic-net-penalizzazione-l1-l2" id="toc-elastic-net-penalizzazione-l1-l2" class="nav-link" data-scroll-target="#elastic-net-penalizzazione-l1-l2">Elastic Net (penalizzazione L1 + L2)</a></li>
  </ul></li>
  <li><a href="#double-descent" id="toc-double-descent" class="nav-link" data-scroll-target="#double-descent">Double Descent</a></li>
  <li><a href="#regressione-polinomiale" id="toc-regressione-polinomiale" class="nav-link" data-scroll-target="#regressione-polinomiale">Regressione Polinomiale</a></li>
  <li><a href="#regressione-pesata" id="toc-regressione-pesata" class="nav-link" data-scroll-target="#regressione-pesata">Regressione Pesata</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../th/01. Richiami di probabilità.html">Theory</a></li><li class="breadcrumb-item"><a href="../th/11. Selezione di Variabili e Regolarizzazione nella Regressione.html">Selezione di Variabili e Regolarizzazione nella Regressione</a></li></ol></nav></header>




<section id="selezione-di-variabili-e-regolarizzazione-nella-regressione" class="level1">
<h1>Selezione di Variabili e Regolarizzazione nella Regressione</h1>
<section id="metodi-stepwise" class="level2">
<h2 class="anchored" data-anchor-id="metodi-stepwise">Metodi Stepwise</h2>
<p>I <strong>metodi stepwise</strong> sono procedure automatiche per la selezione delle variabili in un modello di regressione. L’obiettivo è costruire un modello che sia sufficientemente <strong>parsimonioso</strong>, evitando variabili inutili, ma che mantenga una buona <strong>capacità di adattamento</strong> ai dati.</p>
<p>Nel <strong>backward stepwise</strong> si parte dal modello più complesso possibile, che include tutte le <span class="math inline">\(p\)</span> variabili esplicative. A ogni iterazione viene rimossa la variabile meno significativa, tipicamente quella con il contributo statistico più debole, finché tutte le variabili rimanenti soddisfano un criterio di significatività prefissato.</p>
<p>Nel <strong>forward stepwise</strong>, invece, si parte dal modello nullo, privo di regressori. Le variabili vengono aggiunte una alla volta, scegliendo a ogni passo quella che produce il maggiore miglioramento del modello secondo un criterio statistico. Il procedimento si arresta quando nessuna variabile candidata apporta un miglioramento ritenuto significativo.</p>
<p>Il metodo <strong>misto</strong> (o stepwise propriamente detto) combina i due approcci. L’inclusione delle variabili avviene in modo analogo al forward, ma dopo ogni nuova aggiunta si verifica se alcune delle variabili già presenti siano diventate non significative. In tal caso, queste possono essere rimosse, rendendo il procedimento più flessibile.</p>
<p>Nella pratica, i software statistici non si basano sempre direttamente sui p-value, ma utilizzano spesso soglie sul test <strong>F</strong>, note come <em>F to enter</em> e <em>F to remove</em>. Tali soglie sono equivalenti all’introduzione di livelli di significatività <span class="math inline">\(\alpha_{\text{in}}\)</span> per l’ingresso e <span class="math inline">\(\alpha_{\text{out}}\)</span> per l’uscita delle variabili. Poiché le decisioni dipendono dai valori scelti per queste</p>
<section id="metodo-backward" class="level3">
<h3 class="anchored" data-anchor-id="metodo-backward">Metodo Backward</h3>
<p>Il <strong>metodo backward</strong> per la selezione delle variabili si fonda sui <strong>p-value</strong> associati ai test d’ipotesi sui singoli coefficienti di regressione. Per ciascun regressore si considera il test:</p>
<p><span class="math display">\[
H_0:\ \beta_j = 0 \quad \text{contro} \quad H_1:\ \beta_j \neq 0,
\]</span></p>
<p>che verifica se la variabile <span class="math inline">\(X_j\)</span> fornisce un contributo statisticamente significativo al modello, una volta tenute fisse le altre.</p>
<p>Dal punto di vista operativo, si parte dal <strong>modello completo</strong>, contenente tutte le <span class="math inline">\(p\)</span> variabili esplicative. A ogni iterazione si esaminano i p-value stimati <span class="math inline">\(\alpha_j^*\)</span> e si decide se mantenere o rimuovere una variabile in base a soglie prefissate. Una prassi comune prevede che, se <span class="math inline">\(\alpha_j^* &lt; 0.001\)</span>, la variabile venga chiaramente mantenuta nel modello; in contesti più conservativi si può adottare una correzione di Bonferroni, con una soglia approssimativa <span class="math inline">\(\alpha \approx \tfrac{5\%}{p}\)</span>, per tenere conto della molteplicità dei test. Se il p-value rientra in una fascia intermedia, ad esempio <span class="math inline">\(0.1\% \le \alpha_j^* &lt; 30\%\)</span>, la decisione non è netta e spesso la variabile viene comunque mantenuta. Valori elevati, tipicamente <span class="math inline">\(\alpha_j^* \ge 30\%\)</span>, suggeriscono invece che il contributo della variabile sia trascurabile e che essa possa essere eliminata.</p>
<p>L’algoritmo procede rimuovendo, a ogni passo, la variabile con il <strong>p-value più alto</strong>, ricalcolando poi il modello ridotto e i nuovi p-value. Il procedimento si arresta quando tutte le variabili rimanenti risultano significative secondo la soglia scelta.</p>
<p>Un aspetto critico è la <strong>multicollinearità</strong>. In presenza di forti correlazioni tra i regressori, gli stimatori dei coefficienti diventano instabili e i p-value possono risultare artificialmente elevati. Di conseguenza, il metodo backward può eliminare variabili che sarebbero rilevanti dal punto di vista sostantivo, rendendo la selezione fortemente dipendente dalla struttura di correlazione dei dati.</p>
</section>
<section id="metodo-forward" class="level3">
<h3 class="anchored" data-anchor-id="metodo-forward">Metodo Forward</h3>
<p>Il <strong>metodo forward</strong> costruisce il modello in modo incrementale, aggiungendo una variabile alla volta. Si parte dal <strong>modello nullo</strong>, che contiene solo l’intercetta, e si valuta quale variabile, tra quelle non ancora incluse, produce il maggior miglioramento del modello.</p>
<p>Il miglioramento può essere misurato tramite <strong>indicatori globali di adattamento</strong>, come la riduzione dell’errore standard della regressione <span class="math inline">\(S_e\)</span> oppure l’aumento del coefficiente di determinazione <span class="math inline">\(R^2\)</span>. Parallelamente, si richiede che l’ingresso della variabile sia supportato da una <strong>significatività statistica</strong>, valutata tramite il p-value del coefficiente o tramite un test <strong>F</strong> che confronta il modello corrente con quello arricchito dalla nuova variabile.</p>
<p>La prima variabile inserita è quindi quella che, da sola, spiega meglio la risposta. Successivamente, a ogni iterazione si considera l’aggiunta di una nuova variabile al modello già costruito e si seleziona quella che fornisce il miglior contributo addizionale. Il procedimento si arresta quando nessuna delle variabili rimanenti è in grado di produrre un miglioramento <strong>statisticamente significativo</strong> secondo la soglia scelta.</p>
<p>È importante notare che il metodo forward non riconsidera mai l’esclusione delle variabili già inserite. Per questo motivo, in presenza di <strong>interazioni</strong> o <strong>collinearità</strong> tra regressori, il percorso di selezione può differire sensibilmente da quello del metodo backward. Di conseguenza, forward e backward possono condurre a <strong>modelli finali diversi</strong>, anche partendo dallo stesso insieme iniziale di variabili.</p>
</section>
</section>
<section id="metodi-globali" class="level2">
<h2 class="anchored" data-anchor-id="metodi-globali">Metodi Globali</h2>
<p>I <strong>metodi globali</strong> affrontano il problema della selezione delle variabili valutando <strong>tutti i possibili sottoinsiemi</strong> di regressori. Dato un insieme di <span class="math inline">\(p\)</span> variabili esplicative, ciò equivale a considerare <span class="math inline">\(2^p\)</span> modelli distinti, dal modello nullo a quello completo. Questo approccio è concettualmente più completo rispetto ai metodi stepwise, ma diventa rapidamente <strong>computazionalmente oneroso</strong> all’aumentare di <span class="math inline">\(p\)</span>.</p>
<p>La scelta del modello finale avviene confrontando i diversi sottoinsiemi tramite <strong>criteri globali di bontà del modello</strong>. Un primo criterio è il minimo <strong>errore standard della regressione</strong> <span class="math inline">\(S_e\)</span>, che privilegia modelli con residui mediamente più piccoli. Un’alternativa è il massimo <strong><span class="math inline">\(R_a^2\)</span></strong>, il coefficiente di determinazione corretto, che penalizza l’aggiunta di variabili superflue e riduce l’ottimismo del semplice <span class="math inline">\(R^2\)</span>.</p>
<p>Sono molto utilizzati anche criteri informativi come <strong>AIC</strong> e <strong>BIC</strong>, che bilanciano qualità dell’adattamento e complessità del modello introducendo una penalizzazione esplicita per il numero di parametri. In generale, l’AIC tende a favorire modelli più ricchi, mentre il BIC applica una penalizzazione più severa e porta a modelli più parsimoniosi.</p>
<p>Un approccio sempre più rilevante è la valutazione delle prestazioni in <strong>validazione</strong>, ad esempio tramite il valore di <span class="math inline">\(R^2\)</span> su un validation set, l’errore di previsione o misure come l’MSE stimato con <strong>cross-validation</strong>. Questo sposta l’attenzione dall’adattamento ai dati osservati alla capacità predittiva del modello.</p>
<p>Un aspetto cruciale è che tutti questi indicatori sono affetti da <strong>variabilità campionaria</strong>. In assenza di una validazione esterna o di tecniche di ri-campionamento, la scelta del modello può risultare instabile, soprattutto quando le differenze tra modelli sono piccole o quando i regressori sono fortemente correlati.</p>
</section>
<section id="coefficienti-di-determinazione" class="level2">
<h2 class="anchored" data-anchor-id="coefficienti-di-determinazione">Coefficienti di Determinazione</h2>
<section id="r2" class="level3">
<h3 class="anchored" data-anchor-id="r2"><span class="math inline">\(R^2\)</span></h3>
<p>Il coefficiente di determinazione <span class="math inline">\(R^2\)</span> misura la <strong>quota di variabilità totale della risposta spiegata dal modello</strong>. È definito come</p>
<p><span class="math display">\[
R^2 = 1 - \frac{SSR}{SSY}, \qquad
SSR = \sum_{i=1}^n (Y_i - \hat{Y}_i)^2, \qquad
SSY = \sum_{i=1}^n (Y_i - \bar{Y})^2.
\]</span></p>
<p>In questa notazione, <span class="math inline">\(SSR\)</span> rappresenta la <strong>somma dei residui al quadrato</strong> (<em>sum of squared residuals</em>), mentre <span class="math inline">\(SSY\)</span> è la somma dei quadrati totali rispetto alla media campionaria. Il valore di <span class="math inline">\(R^2\)</span> appartiene all’intervallo <span class="math inline">\([0,1]\)</span>: valori prossimi a <span class="math inline">\(1\)</span> indicano che il modello spiega una grande parte della variabilità osservata, mentre valori prossimi a <span class="math inline">\(0\)</span> indicano una capacità esplicativa ridotta.</p>
<p>Una proprietà importante è che <span class="math inline">\(R^2\)</span> <strong>non penalizza l’aggiunta di nuove variabili</strong>. Inserendo ulteriori regressori, <span class="math inline">\(SSR\)</span> non può aumentare e quindi <span class="math inline">\(R^2\)</span> può solo crescere o rimanere invariato, anche quando le nuove variabili non apportano un contributo informativo reale.</p>
</section>
<section id="r_a2" class="level3">
<h3 class="anchored" data-anchor-id="r_a2"><span class="math inline">\(R_a^2\)</span></h3>
<p>Il coefficiente di determinazione corretto <span class="math inline">\(R_a^2\)</span> introduce una correzione che tiene conto del <strong>numero di parametri stimati</strong> nel modello, con l’obiettivo di ridurre il rischio di overfitting. È definito come</p>
<p><span class="math display">\[
R_a^2 = 1 - \frac{S_e^2}{S_Y^2}, \qquad
S_e^2 = \frac{SSR}{n - p - 1}, \qquad
S_Y^2 = \frac{SSY}{n - 1},
\]</span></p>
<p>dove <span class="math inline">\(p\)</span> è il numero di regressori esclusa l’intercetta. Qui <span class="math inline">\(S_e^2\)</span> è una stima della varianza dell’errore, mentre <span class="math inline">\(S_Y^2\)</span> rappresenta la varianza campionaria della risposta.</p>
<p>A differenza di <span class="math inline">\(R^2\)</span>, il valore di <span class="math inline">\(R_a^2\)</span> <strong>aumenta solo se la variabile aggiunta migliora effettivamente il modello</strong>, compensando la perdita di gradi di libertà dovuta all’introduzione di un nuovo parametro. Per questo motivo, <span class="math inline">\(R_a^2\)</span> è spesso preferito a <span class="math inline">\(R^2\)</span> nei confronti tra modelli con diverso numero di regressori.</p>
</section>
</section>
<section id="overfitting" class="level2">
<h2 class="anchored" data-anchor-id="overfitting">Overfitting</h2>
<p>L’<strong>overfitting</strong> si verifica quando un modello si adatta in modo eccessivo ai dati di training, catturando anche il rumore campionario, ma mostra una <strong>scarsa capacità di generalizzazione</strong> su nuovi dati. In questi casi il modello presenta prestazioni apparentemente molto buone sul campione utilizzato per la stima, ma errori elevati in previsione.</p>
<p>Un primo fattore chiave è il rapporto tra numerosità campionaria e complessità del modello. Mantenere un buon rapporto <strong>dati/variabili</strong>, espresso come <span class="math inline">\(N/P \gg 1\)</span>, riduce il rischio che il modello disponga di troppi gradi di libertà rispetto alle informazioni effettivamente disponibili nei dati.</p>
<p>In presenza di dati molto rumorosi è spesso preferibile adottare modelli più <strong>parsimoniosi</strong>, evitando l’inclusione indiscriminata di regressori. In questo contesto, il metodo forward può talvolta risultare meno aggressivo del backward, poiché inserisce solo variabili con un contributo incrementale evidente; tuttavia, questa non è una regola generale e il comportamento dipende fortemente dalla struttura dei dati e dalle correlazioni tra regressori.</p>
<p>Strumenti fondamentali per il controllo dell’overfitting sono la <strong>validazione</strong>, ad esempio tramite validation set o cross-validation, e la <strong>regolarizzazione</strong>, che introduce penalizzazioni sui coefficienti per limitare la complessità del modello e stabilizzare le stime.</p>
</section>
<section id="validazione" class="level2">
<h2 class="anchored" data-anchor-id="validazione">Validazione</h2>
<p>La <strong>validazione</strong> serve a valutare la capacità di <strong>generalizzazione</strong> di un modello, cioè quanto bene esso si comporti su dati non utilizzati nella stima. L’idea di fondo è separare, in modo esplicito o implicito, la fase di apprendimento da quella di valutazione.</p>
<p>Un primo approccio è l’uso di un <strong>validation set</strong>, in cui una frazione dei dati, tipicamente intorno al 10–20%, viene tenuta da parte e non utilizzata per stimare il modello. Il modello è addestrato sul training set e valutato sui dati lasciati fuori, ottenendo una stima diretta dell’errore di previsione.</p>
<p>Un metodo più stabile è la <strong>cross-validation <span class="math inline">\(k\)</span>-fold</strong>. Il campione viene suddiviso in <span class="math inline">\(k\)</span> blocchi di dimensione simile; a ogni iterazione uno dei blocchi funge da validation set mentre i restanti <span class="math inline">\(k-1\)</span> sono usati per il training. L’errore di generalizzazione è stimato mediando le prestazioni ottenute sui diversi blocchi. Questo approccio riduce la dipendenza della valutazione da una singola partizione dei dati.</p>
<p>Il caso limite della cross-validation è la <strong>leave-one-out cross-validation (LOOCV)</strong>, in cui si pone <span class="math inline">\(k=n\)</span>. A ogni iterazione si lascia fuori un solo punto e si stima il modello sugli altri <span class="math inline">\(n-1\)</span> dati. La LOOCV utilizza quasi tutta l’informazione disponibile per il training, ma può risultare computazionalmente costosa e con varianza elevata della stima dell’errore.</p>
<p>È importante distinguere la validazione predittiva da altre tecniche di ri-campionamento. Il termine <strong>Jackknife</strong> è concettualmente correlato, ma ha uno scopo diverso: è utilizzato principalmente per stimare bias e varianza di statistiche, non per valutare le prestazioni predittive di un modello. In ambito di validazione, il riferimento corretto è quindi la LOOCV, non il Jackknife.</p>
</section>
<section id="regolarizzazione" class="level2">
<h2 class="anchored" data-anchor-id="regolarizzazione">Regolarizzazione</h2>
<p>La <strong>regolarizzazione</strong> introduce una penalizzazione sui coefficienti del modello con l’obiettivo di <strong>contenere la complessità</strong>, stabilizzare le stime e prevenire coefficienti di ampiezza eccessiva, fenomeno tipico in presenza di multicollinearità o di un numero elevato di regressori rispetto ai dati disponibili.</p>
<section id="ridge-regression-penalizzazione-l2" class="level3">
<h3 class="anchored" data-anchor-id="ridge-regression-penalizzazione-l2">Ridge Regression (penalizzazione L2)</h3>
<p>La <strong>Ridge Regression</strong> aggiunge alla funzione di perdita una penalizzazione proporzionale alla somma dei quadrati dei coefficienti. In genere l’intercetta non viene penalizzata. Il problema di ottimizzazione è</p>
<p><span class="math display">\[
\min_{\mathbf B}\ \frac{1}{n}\sum_{i=1}^n\left(Y_i-\sum_{j=1}^p B_j X_{ij}\right)^2
\;+\;
\lambda\sum_{j=1}^p B_j^2.
\]</span></p>
<p>La penalizzazione L2 tende a <strong>ridurre</strong> l’ampiezza dei coefficienti, ma non li annulla esattamente. Il risultato è un modello più stabile, in cui le variabili fortemente correlate condividono il peso esplicativo invece di competere in modo instabile.</p>
</section>
<section id="lasso-regression-penalizzazione-l1" class="level3">
<h3 class="anchored" data-anchor-id="lasso-regression-penalizzazione-l1">Lasso Regression (penalizzazione L1)</h3>
<p>La <strong>Lasso Regression</strong> utilizza una penalizzazione basata sulla somma dei <strong>valori assoluti</strong> dei coefficienti:</p>
<p><span class="math display">\[
\min_{\mathbf B}\ \frac{1}{n}\sum_{i=1}^n\left(Y_i-\sum_{j=1}^p B_j X_{ij}\right)^2
\;+\;
\lambda\sum_{j=1}^p |B_j|.
\]</span></p>
<p>La penalizzazione L1 ha una proprietà distintiva: induce <strong>sparsità</strong> nel vettore dei coefficienti. Alcuni coefficienti vengono spinti esattamente a zero, realizzando di fatto una selezione automatica delle variabili, oltre alla regolarizzazione.</p>
</section>
<section id="elastic-net-penalizzazione-l1-l2" class="level3">
<h3 class="anchored" data-anchor-id="elastic-net-penalizzazione-l1-l2">Elastic Net (penalizzazione L1 + L2)</h3>
<p>L’<strong>Elastic Net</strong> combina le penalizzazioni L1 e L2, unendo i vantaggi di Ridge e Lasso:</p>
<p><span class="math display">\[
\min_{\mathbf B}\ \frac{1}{n}\sum_{i=1}^n\left(Y_i-\sum_{j=1}^p B_j X_{ij}\right)^2
\;+\;
\lambda_1\sum_{j=1}^p |B_j|
\;+\;
\lambda_2\sum_{j=1}^p B_j^2.
\]</span></p>
<p>Questa formulazione è particolarmente utile quando i regressori sono numerosi e fortemente correlati: la componente L2 stabilizza le stime, mentre la componente L1 consente la selezione delle variabili.</p>
<p>Dal punto di vista pratico, i regressori vengono <strong>standardizzati</strong> per rendere confrontabili le penalizzazioni tra coefficienti, l’intercetta non viene penalizzata e i parametri di regolarizzazione <span class="math inline">\(\lambda\)</span> (e il bilanciamento tra L1 e L2 nell’Elastic Net) vengono scelti tramite <strong>cross-validation</strong>, ottimizzando le prestazioni predittive del modello.</p>
</section>
</section>
<section id="double-descent" class="level2">
<h2 class="anchored" data-anchor-id="double-descent">Double Descent</h2>
<p>Il <strong>double descent</strong> è un fenomeno osservato in modelli ad <strong>altissima capacità</strong>, in cui l’errore di generalizzazione non segue l’andamento classico a U, ma mostra due fasi distinte. Al crescere della complessità del modello, l’errore inizialmente <strong>diminuisce</strong>, poi <strong>aumenta</strong> in prossimità della soglia di <strong>interpolazione</strong> (dove il modello riesce a fittare esattamente i dati di training) e infine <strong>ridiscende</strong> quando la capacità continua ad aumentare.</p>
<p>La prima fase corrisponde al regime classico bias–variance: aumentando la complessità si riduce il bias ma cresce la varianza, portando a overfitting. Il picco di errore si verifica tipicamente quando il numero di parametri è comparabile o supera di poco il numero di osservazioni, e il modello interpola i dati di training.</p>
<p>Nel regime successivo, detto <strong>overparameterized</strong>, l’errore di generalizzazione può sorprendentemente diminuire. Questo comportamento è stato osservato soprattutto in presenza di <strong>regolarizzazione implicita</strong>, come quella indotta dagli algoritmi di ottimizzazione (ad esempio gradient descent), dall’early stopping o dalla struttura stessa dei modelli. In questo regime, pur avendo capacità sufficiente per interpolare, il modello tende a convergere verso soluzioni con buone proprietà di generalizzazione.</p>
<p>Il fenomeno del double descent è particolarmente rilevante nei <strong>modelli moderni ad alta dimensionalità</strong>, come le reti neurali profonde e i modelli di grandi dimensioni, e mostra che la relazione tra complessità del modello e generalizzazione è più articolata di quanto suggerito dalla visione classica dell’overfitting.</p>
</section>
<section id="regressione-polinomiale" class="level2">
<h2 class="anchored" data-anchor-id="regressione-polinomiale">Regressione Polinomiale</h2>
<p>La <strong>regressione polinomiale</strong> estende la regressione lineare introducendo <strong>termini polinomiali</strong> delle variabili esplicative, consentendo di modellare relazioni non lineari pur rimanendo in un quadro lineare nei parametri. Nel caso univariato, il modello di grado <span class="math inline">\(d\)</span> è</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 x + \beta_2 x^2 + \dots + \beta_d x^d.
\]</span></p>
<p>Nonostante la non linearità in <span class="math inline">\(x\)</span>, il modello resta lineare rispetto ai coefficienti <span class="math inline">\(\beta_j\)</span>, e può quindi essere stimato con i metodi usuali dei minimi quadrati.</p>
<p>Una regola importante è la <strong>regola gerarchica</strong>: se si include un termine di grado <span class="math inline">\(d\)</span>, è buona pratica includere anche tutti i termini di grado inferiore. Questo garantisce interpretabilità e stabilità del modello, evitando specificazioni incoerenti come la presenza di <span class="math inline">\(x^2\)</span> senza il termine lineare <span class="math inline">\(x\)</span>.</p>
<p>Nel caso multivariato, la regressione polinomiale può includere anche <strong>termini di interazione</strong> tra variabili, ad esempio <span class="math inline">\(x_1 x_2\)</span>, che permettono di modellare effetti combinati in cui l’influenza di una variabile dipende dal livello di un’altra. Anche per le interazioni vale una forma di gerarchia: includere un termine di interazione implica includere i termini principali corrispondenti.</p>
<p>L’aumento del grado polinomiale o del numero di interazioni incrementa rapidamente la complessità del modello e il numero di parametri. Per questo motivo la regressione polinomiale è particolarmente soggetta a <strong>overfitting</strong> quando il grado è troppo elevato rispetto alla numerosità campionaria. In pratica, la scelta del grado e dei termini da includere dovrebbe essere guidata da <strong>validazione</strong> e, quando necessario, da tecniche di <strong>regolarizzazione</strong> per controllare la variabilità delle stime.</p>
</section>
<section id="regressione-pesata" class="level2">
<h2 class="anchored" data-anchor-id="regressione-pesata">Regressione Pesata</h2>
<p>Quando l’ipotesi di <strong>omoschedasticità</strong> non è soddisfatta, cioè quando la varianza degli errori non è costante tra le osservazioni, la stima OLS non è più efficiente. In questi casi si utilizza la <strong>regressione pesata</strong> (<em>Weighted Least Squares</em>, WLS), che assegna pesi diversi alle osservazioni in funzione della loro variabilità.</p>
<p>L’idea è minimizzare una somma dei quadrati dei residui <strong>pesata</strong>:</p>
<p><span class="math display">\[
SSR_W = \sum_{i=1}^n W_i\left(Y_i - \sum_{j=1}^p B_j X_{ij}\right)^2,
\qquad
W_i = \frac{1}{\sigma_i^2},
\]</span></p>
<p>dove <span class="math inline">\(\sigma_i^2\)</span> è la varianza dell’errore associato all’osservazione <span class="math inline">\(i\)</span>-esima. In questo modo, le osservazioni con varianza maggiore ricevono un peso minore e influenzano meno la stima dei coefficienti.</p>
<p>La WLS è equivalente a una trasformazione dei dati. Definendo</p>
<p><span class="math display">\[
\tilde{X}_{ij} = \frac{X_{ij}}{\sigma_i},
\qquad
\tilde{Y}_i = \frac{Y_i}{\sigma_i},
\]</span></p>
<p>il problema di minimizzazione pesata si riconduce a una <strong>regressione OLS</strong> applicata ai dati trasformati. Questa equivalenza chiarisce che la regressione pesata ristabilisce, sui dati trasformati, l’ipotesi di varianza costante degli errori.</p>
<p>In pratica, le varianze <span class="math inline">\(\sigma_i^2\)</span> non sono quasi mai note. In tali situazioni possono essere <strong>stimate</strong>, ad esempio specificando un modello per la varianza in funzione delle covariate o dei valori predetti, e utilizzate per definire i pesi. Il procedimento può essere iterato: si stima il modello, si aggiornano le varianze e i pesi, e si ricalcola la regressione fino a convergenza.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>